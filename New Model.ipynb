{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import multiprocessing as mlp\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Dataframe that was created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('four_classes_cleaned.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Year Term ID_x</th>\n",
       "      <th>Term GPA</th>\n",
       "      <th>Cumul GPA</th>\n",
       "      <th>Term Transfer Hrs</th>\n",
       "      <th>Ps1 Major1 Code</th>\n",
       "      <th>Ps1 Major2 Code</th>\n",
       "      <th>Repeated Flag</th>\n",
       "      <th>Ps1 Acad Standing Desc</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Citizen Country Name</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172789163</td>\n",
       "      <td>20062.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PSY</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172846340</td>\n",
       "      <td>20102.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.70</td>\n",
       "      <td>26.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172857770</td>\n",
       "      <td>20162.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ENG</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172857770</td>\n",
       "      <td>20171.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ENG</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SubjectID  Year Term ID_x  Term GPA  Cumul GPA  Term Transfer Hrs  \\\n",
       "0  172789163         20062.0      0.00       3.07                0.0   \n",
       "1  172846340         20102.0      3.30       2.70               26.0   \n",
       "2  172857770         20162.0      0.00       2.20                0.0   \n",
       "3  172857770         20171.0      0.00       2.20                4.0   \n",
       "4  175397669         19871.0      2.33       2.33               42.0   \n",
       "\n",
       "  Ps1 Major1 Code Ps1 Major2 Code Repeated Flag Ps1 Acad Standing Desc Gender  \\\n",
       "0             PSY               .             N                 ACTIVE      M   \n",
       "1             PSC               .             N              PROBATION      F   \n",
       "2             ENG               .             N                 ACTIVE      M   \n",
       "3             ENG               .             N                 ACTIVE      M   \n",
       "4             PSC               .             N                 ACTIVE      M   \n",
       "\n",
       "  Citizen Country Name Classification  \n",
       "0                  USA              N  \n",
       "1                  USA              N  \n",
       "2                  USA              N  \n",
       "3                  USA              N  \n",
       "4                  USA             NG  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SubjectID', 'Year Term ID_x', 'Term GPA', 'Cumul GPA',\n",
       "       'Term Transfer Hrs', 'Ps1 Major1 Code', 'Ps1 Major2 Code',\n",
       "       'Repeated Flag', 'Ps1 Acad Standing Desc', 'Gender',\n",
       "       'Citizen Country Name', 'Classification'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397031"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(['Ps1 Timestat Code','Ps2 Ofcl Stat Flag','Grade','Ps2 Major1 Code','Unnamed: 0','Cumul Hrs Earned','Year Term ID_y', 'Cumul Hrs GPA','Ps2 Major2 Code', 'Credit Hrs','Reported Grade', 'Dorm Area'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Year Term ID_x</th>\n",
       "      <th>Term GPA</th>\n",
       "      <th>Cumul GPA</th>\n",
       "      <th>Term Transfer Hrs</th>\n",
       "      <th>Ps1 Major1 Code</th>\n",
       "      <th>Ps1 Major2 Code</th>\n",
       "      <th>Repeated Flag</th>\n",
       "      <th>Ps1 Acad Standing Desc</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Citizen Country Name</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172789163</td>\n",
       "      <td>20062.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PSY</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172846340</td>\n",
       "      <td>20102.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.70</td>\n",
       "      <td>26.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172857770</td>\n",
       "      <td>20162.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ENG</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172857770</td>\n",
       "      <td>20171.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ENG</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397026</th>\n",
       "      <td>255137993</td>\n",
       "      <td>20182.0</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.40</td>\n",
       "      <td>16.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397027</th>\n",
       "      <td>255137993</td>\n",
       "      <td>20191.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397028</th>\n",
       "      <td>255137993</td>\n",
       "      <td>20192.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397029</th>\n",
       "      <td>255461372</td>\n",
       "      <td>20152.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>79.0</td>\n",
       "      <td>PHY</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397030</th>\n",
       "      <td>255461372</td>\n",
       "      <td>20161.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PHY</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397031 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SubjectID  Year Term ID_x  Term GPA  Cumul GPA  Term Transfer Hrs  \\\n",
       "0       172789163         20062.0      0.00       3.07                0.0   \n",
       "1       172846340         20102.0      3.30       2.70               26.0   \n",
       "2       172857770         20162.0      0.00       2.20                0.0   \n",
       "3       172857770         20171.0      0.00       2.20                4.0   \n",
       "4       175397669         19871.0      2.33       2.33               42.0   \n",
       "...           ...             ...       ...        ...                ...   \n",
       "397026  255137993         20182.0      3.68       3.40               16.0   \n",
       "397027  255137993         20191.0      4.00       3.48                0.0   \n",
       "397028  255137993         20192.0      0.00       3.48                0.0   \n",
       "397029  255461372         20152.0      3.00       3.00               79.0   \n",
       "397030  255461372         20161.0      0.70       2.43                0.0   \n",
       "\n",
       "       Ps1 Major1 Code Ps1 Major2 Code Repeated Flag Ps1 Acad Standing Desc  \\\n",
       "0                  PSY               .             N                 ACTIVE   \n",
       "1                  PSC               .             N              PROBATION   \n",
       "2                  ENG               .             N                 ACTIVE   \n",
       "3                  ENG               .             N                 ACTIVE   \n",
       "4                  PSC               .             N                 ACTIVE   \n",
       "...                ...             ...           ...                    ...   \n",
       "397026              ME               .             N                 ACTIVE   \n",
       "397027              ME               .             N                 ACTIVE   \n",
       "397028              ME               .             N                 ACTIVE   \n",
       "397029             PHY               .             N                 ACTIVE   \n",
       "397030             PHY               .             N                 ACTIVE   \n",
       "\n",
       "       Gender Citizen Country Name Classification  \n",
       "0           M                  USA              N  \n",
       "1           F                  USA              N  \n",
       "2           M                  USA              N  \n",
       "3           M                  USA              N  \n",
       "4           M                  USA             NG  \n",
       "...       ...                  ...            ...  \n",
       "397026      M            HONG KONG              N  \n",
       "397027      M            HONG KONG              N  \n",
       "397028      M            HONG KONG              N  \n",
       "397029      F                  USA             NG  \n",
       "397030      F                  USA             NG  \n",
       "\n",
       "[397031 rows x 12 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe =dataframe.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove \"fake\" zeros from the dataframe (0 term gpa not due to poor academic performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29063"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = dataframe.loc[dataframe['Term GPA']==0].index\n",
    "len(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros =list(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397031/397031 [01:31<00:00, 4352.02it/s]\n"
     ]
    }
   ],
   "source": [
    "real_zeros = []\n",
    "for i in tqdm(range(0,len(dataframe))):\n",
    "    if i in zeros:\n",
    "        if dataframe['Cumul GPA'].iloc[i]>dataframe['Cumul GPA'].iloc[i+1]:\n",
    "            if dataframe['SubjectID'].iloc[i]==dataframe['SubjectID'].iloc[i+1]:\n",
    "                real_zeros.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_zero_index = dataframe.iloc[real_zeros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in real_zeros:\n",
    "    zeros.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe.loc[dataframe['Term GPA']==0]['SubjectID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by Students to better access data per student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = dataframe.groupby(['SubjectID'], as_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Year Term ID_x</th>\n",
       "      <th>Term GPA</th>\n",
       "      <th>Cumul GPA</th>\n",
       "      <th>Term Transfer Hrs</th>\n",
       "      <th>Ps1 Major1 Code</th>\n",
       "      <th>Ps1 Major2 Code</th>\n",
       "      <th>Repeated Flag</th>\n",
       "      <th>Ps1 Acad Standing Desc</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Citizen Country Name</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172846340</td>\n",
       "      <td>20102.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.70</td>\n",
       "      <td>26.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175693463</td>\n",
       "      <td>19972.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>17.0</td>\n",
       "      <td>PSY</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175754600</td>\n",
       "      <td>19901.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BIG</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176716079</td>\n",
       "      <td>19881.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IDE</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20176</th>\n",
       "      <td>252634292</td>\n",
       "      <td>20151.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.39</td>\n",
       "      <td>69.0</td>\n",
       "      <td>OPT</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20177</th>\n",
       "      <td>254575592</td>\n",
       "      <td>20152.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>85.0</td>\n",
       "      <td>ECO</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>F</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20178</th>\n",
       "      <td>254613473</td>\n",
       "      <td>20152.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MST</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>F</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>NT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20179</th>\n",
       "      <td>255137993</td>\n",
       "      <td>20161.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20180</th>\n",
       "      <td>255461372</td>\n",
       "      <td>20152.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>79.0</td>\n",
       "      <td>PHY</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20181 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SubjectID  Year Term ID_x  Term GPA  Cumul GPA  Term Transfer Hrs  \\\n",
       "0      172846340         20102.0      3.30       2.70               26.0   \n",
       "1      175397669         19871.0      2.33       2.33               42.0   \n",
       "2      175693463         19972.0      3.10       3.10               17.0   \n",
       "3      175754600         19901.0      1.70       2.22                0.0   \n",
       "4      176716079         19881.0      2.20       1.95                0.0   \n",
       "...          ...             ...       ...        ...                ...   \n",
       "20176  252634292         20151.0      2.39       2.39               69.0   \n",
       "20177  254575592         20152.0      3.08       3.08               85.0   \n",
       "20178  254613473         20152.0      3.00       3.00               60.0   \n",
       "20179  255137993         20161.0      2.90       2.90                0.0   \n",
       "20180  255461372         20152.0      3.00       3.00               79.0   \n",
       "\n",
       "      Ps1 Major1 Code Ps1 Major2 Code Repeated Flag Ps1 Acad Standing Desc  \\\n",
       "0                 PSC               .             N              PROBATION   \n",
       "1                 PSC               .             N                 ACTIVE   \n",
       "2                 PSY               .             N                 ACTIVE   \n",
       "3                 BIG               .             N                 ACTIVE   \n",
       "4                 IDE               .             N                 ACTIVE   \n",
       "...               ...             ...           ...                    ...   \n",
       "20176             OPT               .             N                 ACTIVE   \n",
       "20177             ECO               .             N                 ACTIVE   \n",
       "20178             MST               .             N                 ACTIVE   \n",
       "20179              ME               .             N                 ACTIVE   \n",
       "20180             PHY               .             N                 ACTIVE   \n",
       "\n",
       "      Gender Citizen Country Name Classification  \n",
       "0          F                  USA              N  \n",
       "1          M                  USA             NG  \n",
       "2          F                  USA              N  \n",
       "3          F                  USA             NG  \n",
       "4          M                  USA             NT  \n",
       "...      ...                  ...            ...  \n",
       "20176      M                  USA             NG  \n",
       "20177      F                CHINA              N  \n",
       "20178      F                CHINA             NT  \n",
       "20179      M            HONG KONG              N  \n",
       "20180      F                  USA             NG  \n",
       "\n",
       "[20181 rows x 12 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut out only first four semesters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_four_semesters = pd.DataFrame(columns=dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20181/20181 [00:07<00:00, 2564.60it/s]\n"
     ]
    }
   ],
   "source": [
    "first_four = []\n",
    "for i in tqdm(dataframe['SubjectID'].unique()):\n",
    "    x= groups.get_group(i)\n",
    "    x= x.iloc[0:4, :]\n",
    "    first_four.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_four_semesters= pd.concat(first_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Year Term ID_x</th>\n",
       "      <th>Term GPA</th>\n",
       "      <th>Cumul GPA</th>\n",
       "      <th>Term Transfer Hrs</th>\n",
       "      <th>Ps1 Major1 Code</th>\n",
       "      <th>Ps1 Major2 Code</th>\n",
       "      <th>Repeated Flag</th>\n",
       "      <th>Ps1 Acad Standing Desc</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Citizen Country Name</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172846340</td>\n",
       "      <td>20102.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.70</td>\n",
       "      <td>26.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>ECO</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>ECO</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>UNC</td>\n",
       "      <td>.</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SubjectID  Year Term ID_x  Term GPA  Cumul GPA  Term Transfer Hrs  \\\n",
       "1  172846340         20102.0      3.30       2.70               26.0   \n",
       "4  175397669         19871.0      2.33       2.33               42.0   \n",
       "5  175397669         19871.0      2.33       2.33               42.0   \n",
       "6  175397669         19871.0      2.33       2.33               42.0   \n",
       "7  175397669         19871.0      2.33       2.33               42.0   \n",
       "\n",
       "  Ps1 Major1 Code Ps1 Major2 Code Repeated Flag Ps1 Acad Standing Desc Gender  \\\n",
       "1             PSC               .             N              PROBATION      F   \n",
       "4             PSC               .             N                 ACTIVE      M   \n",
       "5             ECO               .             N                 ACTIVE      M   \n",
       "6             ECO               .             N              PROBATION      M   \n",
       "7             UNC               .             N              PROBATION      M   \n",
       "\n",
       "  Citizen Country Name Classification  \n",
       "1                  USA              N  \n",
       "4                  USA             NG  \n",
       "5                  USA             NG  \n",
       "6                  USA             NG  \n",
       "7                  USA             NG  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_four_semesters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffs = first_four_semesters.copy(deep= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240670709    4\n",
       "188907974    4\n",
       "233064863    4\n",
       "192395681    4\n",
       "201566627    4\n",
       "            ..\n",
       "194868080    1\n",
       "194634926    1\n",
       "194484734    1\n",
       "239174936    1\n",
       "192712202    1\n",
       "Name: SubjectID, Length: 20181, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffs['SubjectID'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Columns into more abstract information/ reduces memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubles = pd.read_csv('double.csv', names =['0','ids'])\n",
    "double_list = doubles['ids']\n",
    "ffs['double major']=0\n",
    "ffs.loc[ffs['SubjectID'].isin(double_list), 'double major']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffs = ffs.drop(['Ps1 Major2 Code'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Year Term ID_x</th>\n",
       "      <th>Term GPA</th>\n",
       "      <th>Cumul GPA</th>\n",
       "      <th>Term Transfer Hrs</th>\n",
       "      <th>Ps1 Major1 Code</th>\n",
       "      <th>Repeated Flag</th>\n",
       "      <th>Ps1 Acad Standing Desc</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Citizen Country Name</th>\n",
       "      <th>Classification</th>\n",
       "      <th>double major</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172846340</td>\n",
       "      <td>20102.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.70</td>\n",
       "      <td>26.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>ECO</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>ECO</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>UNC</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397022</th>\n",
       "      <td>255137993</td>\n",
       "      <td>20162.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397023</th>\n",
       "      <td>255137993</td>\n",
       "      <td>20171.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397024</th>\n",
       "      <td>255137993</td>\n",
       "      <td>20172.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397029</th>\n",
       "      <td>255461372</td>\n",
       "      <td>20152.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>79.0</td>\n",
       "      <td>PHY</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397030</th>\n",
       "      <td>255461372</td>\n",
       "      <td>20161.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PHY</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78093 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SubjectID  Year Term ID_x  Term GPA  Cumul GPA  Term Transfer Hrs  \\\n",
       "1       172846340         20102.0      3.30       2.70               26.0   \n",
       "4       175397669         19871.0      2.33       2.33               42.0   \n",
       "5       175397669         19871.0      2.33       2.33               42.0   \n",
       "6       175397669         19871.0      2.33       2.33               42.0   \n",
       "7       175397669         19871.0      2.33       2.33               42.0   \n",
       "...           ...             ...       ...        ...                ...   \n",
       "397022  255137993         20162.0      3.35       3.13                0.0   \n",
       "397023  255137993         20171.0      3.18       3.14                0.0   \n",
       "397024  255137993         20172.0      4.00       3.33                0.0   \n",
       "397029  255461372         20152.0      3.00       3.00               79.0   \n",
       "397030  255461372         20161.0      0.70       2.43                0.0   \n",
       "\n",
       "       Ps1 Major1 Code Repeated Flag Ps1 Acad Standing Desc Gender  \\\n",
       "1                  PSC             N              PROBATION      F   \n",
       "4                  PSC             N                 ACTIVE      M   \n",
       "5                  ECO             N                 ACTIVE      M   \n",
       "6                  ECO             N              PROBATION      M   \n",
       "7                  UNC             N              PROBATION      M   \n",
       "...                ...           ...                    ...    ...   \n",
       "397022              ME             N                 ACTIVE      M   \n",
       "397023              ME             N                 ACTIVE      M   \n",
       "397024              ME             N                 ACTIVE      M   \n",
       "397029             PHY             N                 ACTIVE      F   \n",
       "397030             PHY             N                 ACTIVE      F   \n",
       "\n",
       "       Citizen Country Name Classification  double major  \n",
       "1                       USA              N             1  \n",
       "4                       USA             NG             1  \n",
       "5                       USA             NG             1  \n",
       "6                       USA             NG             1  \n",
       "7                       USA             NG             1  \n",
       "...                     ...            ...           ...  \n",
       "397022            HONG KONG              N             1  \n",
       "397023            HONG KONG              N             1  \n",
       "397024            HONG KONG              N             1  \n",
       "397029                  USA             NG             1  \n",
       "397030                  USA             NG             1  \n",
       "\n",
       "[78093 rows x 12 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probation_counts(model):\n",
    "    for i in tqdm(model['SubjectID'].unique()):\n",
    "        model.loc[model['SubjectID']==i,'Probation term numbers']=model.loc[model['SubjectID']==i]['Ps1 Acad Standing Desc'].value_counts().to_dict().get('PROBATION')\n",
    "    return model\n",
    "def probation(df): \n",
    "    for i in df['SubjectID'].unique():\n",
    "        df.loc[df['SubjectID']==i,'Probation term normalized']= df['Probation term numbers']/((df['SubjectID']==i).sum())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "chunk_size = int(ffs.shape[0]/num_processes)\n",
    "chunks = [ffs.loc[ffs.index[i:i + chunk_size]] for i in range(0, ffs.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=num_processes)\n",
    "result = pool.map(probation_counts, chunks)\n",
    "results = pd.concat(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffs = results.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = multiprocessing.cpu_count()\n",
    "chunk_size = int(ffs.shape[0]/num_processes)\n",
    "chunks = [ffs.loc[ffs.index[i:i + chunk_size]] for i in range(0, ffs.shape[0], chunk_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=num_processes)\n",
    "result = pool.map(probation, chunks)\n",
    "results = pd.concat(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffs = results.copy(deep =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffs = ffs.drop(['Probation term numbers'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffs['Probation term normalized']=ffs['Probation term normalized'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Year Term ID_x</th>\n",
       "      <th>Term GPA</th>\n",
       "      <th>Cumul GPA</th>\n",
       "      <th>Term Transfer Hrs</th>\n",
       "      <th>Ps1 Major1 Code</th>\n",
       "      <th>Repeated Flag</th>\n",
       "      <th>Ps1 Acad Standing Desc</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Citizen Country Name</th>\n",
       "      <th>Classification</th>\n",
       "      <th>double major</th>\n",
       "      <th>Probation term normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172846340</td>\n",
       "      <td>20102.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.70</td>\n",
       "      <td>26.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>ECO</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>ECO</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>175397669</td>\n",
       "      <td>19871.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>42.0</td>\n",
       "      <td>UNC</td>\n",
       "      <td>N</td>\n",
       "      <td>PROBATION</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397022</th>\n",
       "      <td>255137993</td>\n",
       "      <td>20162.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397023</th>\n",
       "      <td>255137993</td>\n",
       "      <td>20171.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397024</th>\n",
       "      <td>255137993</td>\n",
       "      <td>20172.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>M</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397029</th>\n",
       "      <td>255461372</td>\n",
       "      <td>20152.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>79.0</td>\n",
       "      <td>PHY</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397030</th>\n",
       "      <td>255461372</td>\n",
       "      <td>20161.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PHY</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>NG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78093 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SubjectID  Year Term ID_x  Term GPA  Cumul GPA  Term Transfer Hrs  \\\n",
       "1       172846340         20102.0      3.30       2.70               26.0   \n",
       "4       175397669         19871.0      2.33       2.33               42.0   \n",
       "5       175397669         19871.0      2.33       2.33               42.0   \n",
       "6       175397669         19871.0      2.33       2.33               42.0   \n",
       "7       175397669         19871.0      2.33       2.33               42.0   \n",
       "...           ...             ...       ...        ...                ...   \n",
       "397022  255137993         20162.0      3.35       3.13                0.0   \n",
       "397023  255137993         20171.0      3.18       3.14                0.0   \n",
       "397024  255137993         20172.0      4.00       3.33                0.0   \n",
       "397029  255461372         20152.0      3.00       3.00               79.0   \n",
       "397030  255461372         20161.0      0.70       2.43                0.0   \n",
       "\n",
       "       Ps1 Major1 Code Repeated Flag Ps1 Acad Standing Desc Gender  \\\n",
       "1                  PSC             N              PROBATION      F   \n",
       "4                  PSC             N                 ACTIVE      M   \n",
       "5                  ECO             N                 ACTIVE      M   \n",
       "6                  ECO             N              PROBATION      M   \n",
       "7                  UNC             N              PROBATION      M   \n",
       "...                ...           ...                    ...    ...   \n",
       "397022              ME             N                 ACTIVE      M   \n",
       "397023              ME             N                 ACTIVE      M   \n",
       "397024              ME             N                 ACTIVE      M   \n",
       "397029             PHY             N                 ACTIVE      F   \n",
       "397030             PHY             N                 ACTIVE      F   \n",
       "\n",
       "       Citizen Country Name Classification  double major  \\\n",
       "1                       USA              N             1   \n",
       "4                       USA             NG             1   \n",
       "5                       USA             NG             1   \n",
       "6                       USA             NG             1   \n",
       "7                       USA             NG             1   \n",
       "...                     ...            ...           ...   \n",
       "397022            HONG KONG              N             1   \n",
       "397023            HONG KONG              N             1   \n",
       "397024            HONG KONG              N             1   \n",
       "397029                  USA             NG             1   \n",
       "397030                  USA             NG             1   \n",
       "\n",
       "        Probation term normalized  \n",
       "1                             1.0  \n",
       "4                             0.5  \n",
       "5                             0.5  \n",
       "6                             0.5  \n",
       "7                             0.5  \n",
       "...                           ...  \n",
       "397022                        0.0  \n",
       "397023                        0.0  \n",
       "397024                        0.0  \n",
       "397029                        0.0  \n",
       "397030                        0.0  \n",
       "\n",
       "[78093 rows x 13 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode data for learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffs.loc[ffs['Citizen Country Name']!='USA', 'Citizen Country Name']=0\n",
    "ffs.loc[ffs['Citizen Country Name']=='USA', 'Citizen Country Name']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffs.loc[ffs['Classification']=='N', 'Classification']=3\n",
    "ffs.loc[ffs['Classification']=='NT', 'Classification']=2\n",
    "ffs.loc[ffs['Classification']=='TP', 'Classification']=1\n",
    "ffs.loc[ffs['Classification']=='NG', 'Classification']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with Term GPA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ffs.drop(['Classification'], axis =1)\n",
    "y = ffs['Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    68473\n",
       "0     9620\n",
       "Name: Citizen Country Name, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Citizen Country Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['Year Term ID_x', 'Ps1 Acad Standing Desc'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[ffs['Term Transfer Hrs']!=0, 'Term Transfer Hrs']=1\n",
    "X.loc[ffs['Term Transfer Hrs']==0, 'Term Transfer Hrs']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.rename(columns={\"Ps1 Major1 Code\": \"Major\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Term GPA</th>\n",
       "      <th>Cumul GPA</th>\n",
       "      <th>Term Transfer Hrs</th>\n",
       "      <th>Major</th>\n",
       "      <th>Repeated Flag</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Citizen Country Name</th>\n",
       "      <th>double major</th>\n",
       "      <th>Probation term normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172846340</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175397669</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>175397669</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ECO</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>175397669</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ECO</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>175397669</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNC</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397022</th>\n",
       "      <td>255137993</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397023</th>\n",
       "      <td>255137993</td>\n",
       "      <td>3.18</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397024</th>\n",
       "      <td>255137993</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397029</th>\n",
       "      <td>255461372</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PHY</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397030</th>\n",
       "      <td>255461372</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PHY</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78093 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SubjectID  Term GPA  Cumul GPA  Term Transfer Hrs Major Repeated Flag  \\\n",
       "1       172846340      3.30       2.70                1.0   PSC             N   \n",
       "4       175397669      2.33       2.33                1.0   PSC             N   \n",
       "5       175397669      2.33       2.33                1.0   ECO             N   \n",
       "6       175397669      2.33       2.33                1.0   ECO             N   \n",
       "7       175397669      2.33       2.33                1.0   UNC             N   \n",
       "...           ...       ...        ...                ...   ...           ...   \n",
       "397022  255137993      3.35       3.13                0.0    ME             N   \n",
       "397023  255137993      3.18       3.14                0.0    ME             N   \n",
       "397024  255137993      4.00       3.33                0.0    ME             N   \n",
       "397029  255461372      3.00       3.00                1.0   PHY             N   \n",
       "397030  255461372      0.70       2.43                0.0   PHY             N   \n",
       "\n",
       "       Gender Citizen Country Name  double major  Probation term normalized  \n",
       "1           F                    1             1                        1.0  \n",
       "4           M                    1             1                        0.5  \n",
       "5           M                    1             1                        0.5  \n",
       "6           M                    1             1                        0.5  \n",
       "7           M                    1             1                        0.5  \n",
       "...       ...                  ...           ...                        ...  \n",
       "397022      M                    0             1                        0.0  \n",
       "397023      M                    0             1                        0.0  \n",
       "397024      M                    0             1                        0.0  \n",
       "397029      F                    1             1                        0.0  \n",
       "397030      F                    1             1                        0.0  \n",
       "\n",
       "[78093 rows x 10 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(data = X, columns= ['Major', 'Repeated Flag', 'Gender'],  dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X.columns:\n",
    "    X[i]= X[i]/X[i].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubjectID               0\n",
       "Term GPA                0\n",
       "Cumul GPA               0\n",
       "Term Transfer Hrs       0\n",
       "Citizen Country Name    0\n",
       "                       ..\n",
       "Major_WS                0\n",
       "Repeated Flag_N         0\n",
       "Repeated Flag_Y         0\n",
       "Gender_F                0\n",
       "Gender_M                0\n",
       "Length: 108, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= pd.get_dummies(data = y, columns = ['Classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=108, units=64, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=32, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(activation= 'relu', input_dim = 108, units = 64, init = 'uniform'))\n",
    "classifier.add(Dense(activation= 'relu', units = 64, init = 'uniform'))\n",
    "classifier.add(Dense(activation= 'relu', units = 32, init = 'uniform'))\n",
    "classifier.add(Dense(activation= 'relu', units = 16, init = 'uniform'))\n",
    "classifier.add(Dense(activation= 'softmax', units = 4, init = 'uniform'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "78093/78093 [==============================] - 2s 28us/step - loss: 1.3254 - accuracy: 0.5656\n",
      "Epoch 2/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.9841 - accuracy: 0.5763\n",
      "Epoch 3/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.9518 - accuracy: 0.5763\n",
      "Epoch 4/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.9348 - accuracy: 0.5764\n",
      "Epoch 5/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.9197 - accuracy: 0.5826\n",
      "Epoch 6/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.9133 - accuracy: 0.5892\n",
      "Epoch 7/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.9104 - accuracy: 0.5952\n",
      "Epoch 8/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.9070 - accuracy: 0.6008\n",
      "Epoch 9/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.9051 - accuracy: 0.6027\n",
      "Epoch 10/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.9020 - accuracy: 0.6049\n",
      "Epoch 11/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.9001 - accuracy: 0.6055\n",
      "Epoch 12/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8995 - accuracy: 0.6056\n",
      "Epoch 13/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8979 - accuracy: 0.6059\n",
      "Epoch 14/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8968 - accuracy: 0.6063\n",
      "Epoch 15/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8954 - accuracy: 0.6062\n",
      "Epoch 16/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8952 - accuracy: 0.6074\n",
      "Epoch 17/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8940 - accuracy: 0.6075\n",
      "Epoch 18/400\n",
      "78093/78093 [==============================] - 2s 28us/step - loss: 0.8930 - accuracy: 0.6078\n",
      "Epoch 19/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8920 - accuracy: 0.6089\n",
      "Epoch 20/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8909 - accuracy: 0.6085\n",
      "Epoch 21/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8904 - accuracy: 0.6092\n",
      "Epoch 22/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8895 - accuracy: 0.6090\n",
      "Epoch 23/400\n",
      "78093/78093 [==============================] - 2s 28us/step - loss: 0.8888 - accuracy: 0.6098\n",
      "Epoch 24/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8893 - accuracy: 0.6101\n",
      "Epoch 25/400\n",
      "78093/78093 [==============================] - 2s 28us/step - loss: 0.8880 - accuracy: 0.6102\n",
      "Epoch 26/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8870 - accuracy: 0.6131\n",
      "Epoch 27/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8868 - accuracy: 0.6147\n",
      "Epoch 28/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8866 - accuracy: 0.6160\n",
      "Epoch 29/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8860 - accuracy: 0.6154\n",
      "Epoch 30/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8863 - accuracy: 0.6153\n",
      "Epoch 31/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8848 - accuracy: 0.6163\n",
      "Epoch 32/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8843 - accuracy: 0.6162\n",
      "Epoch 33/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8840 - accuracy: 0.6169\n",
      "Epoch 34/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8846 - accuracy: 0.6163\n",
      "Epoch 35/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8849 - accuracy: 0.6164\n",
      "Epoch 36/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8829 - accuracy: 0.6178\n",
      "Epoch 37/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8827 - accuracy: 0.6171\n",
      "Epoch 38/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8822 - accuracy: 0.6179\n",
      "Epoch 39/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8817 - accuracy: 0.6179\n",
      "Epoch 40/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8816 - accuracy: 0.6181\n",
      "Epoch 41/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8810 - accuracy: 0.6183\n",
      "Epoch 42/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8812 - accuracy: 0.6181\n",
      "Epoch 43/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8806 - accuracy: 0.6187\n",
      "Epoch 44/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8798 - accuracy: 0.6187\n",
      "Epoch 45/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8800 - accuracy: 0.6185\n",
      "Epoch 46/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8795 - accuracy: 0.6189\n",
      "Epoch 47/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8791 - accuracy: 0.6192\n",
      "Epoch 48/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8791 - accuracy: 0.6194\n",
      "Epoch 49/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8791 - accuracy: 0.6198\n",
      "Epoch 50/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8788 - accuracy: 0.6188\n",
      "Epoch 51/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8790 - accuracy: 0.6197\n",
      "Epoch 52/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8778 - accuracy: 0.6200\n",
      "Epoch 53/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8779 - accuracy: 0.6203\n",
      "Epoch 54/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8778 - accuracy: 0.6201\n",
      "Epoch 55/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8775 - accuracy: 0.6200\n",
      "Epoch 56/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8769 - accuracy: 0.6196\n",
      "Epoch 57/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8769 - accuracy: 0.6200\n",
      "Epoch 58/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8759 - accuracy: 0.6210\n",
      "Epoch 59/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8759 - accuracy: 0.6208\n",
      "Epoch 60/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8759 - accuracy: 0.6212\n",
      "Epoch 61/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8757 - accuracy: 0.6211\n",
      "Epoch 62/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8753 - accuracy: 0.6211\n",
      "Epoch 63/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8757 - accuracy: 0.6212\n",
      "Epoch 64/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8748 - accuracy: 0.6211\n",
      "Epoch 65/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8745 - accuracy: 0.6208\n",
      "Epoch 66/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8749 - accuracy: 0.6216\n",
      "Epoch 67/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8739 - accuracy: 0.6218\n",
      "Epoch 68/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8736 - accuracy: 0.6220\n",
      "Epoch 69/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8736 - accuracy: 0.6217\n",
      "Epoch 70/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8736 - accuracy: 0.6222\n",
      "Epoch 71/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8734 - accuracy: 0.6218\n",
      "Epoch 72/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8737 - accuracy: 0.6213\n",
      "Epoch 73/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8734 - accuracy: 0.6218\n",
      "Epoch 74/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8735 - accuracy: 0.6219\n",
      "Epoch 75/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8734 - accuracy: 0.6222\n",
      "Epoch 76/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8724 - accuracy: 0.6224\n",
      "Epoch 77/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8726 - accuracy: 0.6221\n",
      "Epoch 78/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8725 - accuracy: 0.6216\n",
      "Epoch 79/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8715 - accuracy: 0.6223\n",
      "Epoch 80/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8713 - accuracy: 0.6230\n",
      "Epoch 81/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8719 - accuracy: 0.6224\n",
      "Epoch 82/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8715 - accuracy: 0.6230\n",
      "Epoch 83/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8711 - accuracy: 0.6229\n",
      "Epoch 84/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8716 - accuracy: 0.6223\n",
      "Epoch 85/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8727 - accuracy: 0.6227\n",
      "Epoch 86/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8709 - accuracy: 0.6239\n",
      "Epoch 87/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8714 - accuracy: 0.6228\n",
      "Epoch 88/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8703 - accuracy: 0.6239\n",
      "Epoch 89/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8704 - accuracy: 0.6237\n",
      "Epoch 90/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8700 - accuracy: 0.6235\n",
      "Epoch 91/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8691 - accuracy: 0.6244\n",
      "Epoch 92/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8691 - accuracy: 0.6239\n",
      "Epoch 93/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8694 - accuracy: 0.6237\n",
      "Epoch 94/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8689 - accuracy: 0.6243\n",
      "Epoch 95/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8685 - accuracy: 0.6242\n",
      "Epoch 96/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8689 - accuracy: 0.6239\n",
      "Epoch 97/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8686 - accuracy: 0.6248\n",
      "Epoch 98/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8680 - accuracy: 0.6246\n",
      "Epoch 99/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8680 - accuracy: 0.6247\n",
      "Epoch 100/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8676 - accuracy: 0.6247\n",
      "Epoch 101/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8672 - accuracy: 0.6252\n",
      "Epoch 102/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8674 - accuracy: 0.6248\n",
      "Epoch 103/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8668 - accuracy: 0.6247\n",
      "Epoch 104/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8670 - accuracy: 0.6246\n",
      "Epoch 105/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8672 - accuracy: 0.6250\n",
      "Epoch 106/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8665 - accuracy: 0.6258\n",
      "Epoch 107/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8676 - accuracy: 0.6255\n",
      "Epoch 108/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8663 - accuracy: 0.6257\n",
      "Epoch 109/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8658 - accuracy: 0.6256\n",
      "Epoch 110/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8653 - accuracy: 0.6264\n",
      "Epoch 111/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8654 - accuracy: 0.6260\n",
      "Epoch 112/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8647 - accuracy: 0.6256\n",
      "Epoch 113/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8651 - accuracy: 0.6255\n",
      "Epoch 114/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8647 - accuracy: 0.6260\n",
      "Epoch 115/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8652 - accuracy: 0.6262\n",
      "Epoch 116/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8650 - accuracy: 0.6259\n",
      "Epoch 117/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8643 - accuracy: 0.6253\n",
      "Epoch 118/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8647 - accuracy: 0.6251\n",
      "Epoch 119/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8658 - accuracy: 0.6261\n",
      "Epoch 120/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8639 - accuracy: 0.6260\n",
      "Epoch 121/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8641 - accuracy: 0.6260\n",
      "Epoch 122/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8639 - accuracy: 0.6259\n",
      "Epoch 123/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8642 - accuracy: 0.6257\n",
      "Epoch 124/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8628 - accuracy: 0.6265\n",
      "Epoch 125/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8633 - accuracy: 0.6263\n",
      "Epoch 126/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8631 - accuracy: 0.6268\n",
      "Epoch 127/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8629 - accuracy: 0.6261\n",
      "Epoch 128/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8626 - accuracy: 0.6260\n",
      "Epoch 129/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8627 - accuracy: 0.6260\n",
      "Epoch 130/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8627 - accuracy: 0.6263\n",
      "Epoch 131/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8617 - accuracy: 0.6270\n",
      "Epoch 132/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8617 - accuracy: 0.6270\n",
      "Epoch 133/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8621 - accuracy: 0.6270\n",
      "Epoch 134/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8629 - accuracy: 0.6271\n",
      "Epoch 135/400\n",
      "78093/78093 [==============================] - 2s 28us/step - loss: 0.8627 - accuracy: 0.6264\n",
      "Epoch 136/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8619 - accuracy: 0.6268\n",
      "Epoch 137/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8609 - accuracy: 0.6275\n",
      "Epoch 138/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8609 - accuracy: 0.6271\n",
      "Epoch 139/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8610 - accuracy: 0.6272\n",
      "Epoch 140/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8612 - accuracy: 0.6269\n",
      "Epoch 141/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8612 - accuracy: 0.6272\n",
      "Epoch 142/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8603 - accuracy: 0.6273\n",
      "Epoch 143/400\n",
      "78093/78093 [==============================] - 2s 29us/step - loss: 0.8600 - accuracy: 0.6281\n",
      "Epoch 144/400\n",
      "78093/78093 [==============================] - 2s 28us/step - loss: 0.8594 - accuracy: 0.6276\n",
      "Epoch 145/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8597 - accuracy: 0.6272\n",
      "Epoch 146/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8598 - accuracy: 0.6272\n",
      "Epoch 147/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8600 - accuracy: 0.6280\n",
      "Epoch 148/400\n",
      "78093/78093 [==============================] - 2s 28us/step - loss: 0.8593 - accuracy: 0.6281\n",
      "Epoch 149/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8592 - accuracy: 0.6282\n",
      "Epoch 150/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8595 - accuracy: 0.6281\n",
      "Epoch 151/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8593 - accuracy: 0.6280\n",
      "Epoch 152/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8585 - accuracy: 0.6282\n",
      "Epoch 153/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8589 - accuracy: 0.6276\n",
      "Epoch 154/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8579 - accuracy: 0.6284\n",
      "Epoch 155/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8581 - accuracy: 0.6279\n",
      "Epoch 156/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8582 - accuracy: 0.6275\n",
      "Epoch 157/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8600 - accuracy: 0.6272\n",
      "Epoch 158/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8577 - accuracy: 0.6282\n",
      "Epoch 159/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8577 - accuracy: 0.6289\n",
      "Epoch 160/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8577 - accuracy: 0.6283\n",
      "Epoch 161/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8564 - accuracy: 0.6288\n",
      "Epoch 162/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8562 - accuracy: 0.6292\n",
      "Epoch 163/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8563 - accuracy: 0.6295\n",
      "Epoch 164/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8566 - accuracy: 0.6287\n",
      "Epoch 165/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8562 - accuracy: 0.6289\n",
      "Epoch 166/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8561 - accuracy: 0.6294\n",
      "Epoch 167/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8566 - accuracy: 0.6285\n",
      "Epoch 168/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8574 - accuracy: 0.6286\n",
      "Epoch 169/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8551 - accuracy: 0.6294\n",
      "Epoch 170/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8550 - accuracy: 0.6296\n",
      "Epoch 171/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8548 - accuracy: 0.6298\n",
      "Epoch 172/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8554 - accuracy: 0.6297\n",
      "Epoch 173/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8544 - accuracy: 0.6293\n",
      "Epoch 174/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8551 - accuracy: 0.6297\n",
      "Epoch 175/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8549 - accuracy: 0.6297\n",
      "Epoch 176/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8541 - accuracy: 0.6300\n",
      "Epoch 177/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8543 - accuracy: 0.6292\n",
      "Epoch 178/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8537 - accuracy: 0.6306\n",
      "Epoch 179/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8537 - accuracy: 0.6300\n",
      "Epoch 180/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8550 - accuracy: 0.6294\n",
      "Epoch 181/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8534 - accuracy: 0.6296\n",
      "Epoch 182/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8532 - accuracy: 0.6292\n",
      "Epoch 183/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8534 - accuracy: 0.6300\n",
      "Epoch 184/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8528 - accuracy: 0.6308\n",
      "Epoch 185/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8518 - accuracy: 0.6305\n",
      "Epoch 186/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8522 - accuracy: 0.6299\n",
      "Epoch 187/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8515 - accuracy: 0.6307\n",
      "Epoch 188/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8515 - accuracy: 0.6310\n",
      "Epoch 189/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8515 - accuracy: 0.6306\n",
      "Epoch 190/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8510 - accuracy: 0.6312\n",
      "Epoch 191/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8528 - accuracy: 0.6306\n",
      "Epoch 192/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8516 - accuracy: 0.6306\n",
      "Epoch 193/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8521 - accuracy: 0.6304\n",
      "Epoch 194/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8507 - accuracy: 0.6312\n",
      "Epoch 195/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8521 - accuracy: 0.6296\n",
      "Epoch 196/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8502 - accuracy: 0.6314\n",
      "Epoch 197/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8498 - accuracy: 0.6316\n",
      "Epoch 198/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8496 - accuracy: 0.6309\n",
      "Epoch 199/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8499 - accuracy: 0.6312\n",
      "Epoch 200/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8492 - accuracy: 0.6315\n",
      "Epoch 201/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8499 - accuracy: 0.6316\n",
      "Epoch 202/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8492 - accuracy: 0.6315\n",
      "Epoch 203/400\n",
      "78093/78093 [==============================] - 2s 27us/step - loss: 0.8493 - accuracy: 0.6316\n",
      "Epoch 204/400\n",
      "78093/78093 [==============================] - 2s 28us/step - loss: 0.8483 - accuracy: 0.6316\n",
      "Epoch 205/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8479 - accuracy: 0.6319\n",
      "Epoch 206/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8480 - accuracy: 0.6317\n",
      "Epoch 207/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8485 - accuracy: 0.6320\n",
      "Epoch 208/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8485 - accuracy: 0.6318\n",
      "Epoch 209/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8483 - accuracy: 0.6317\n",
      "Epoch 210/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8479 - accuracy: 0.6322\n",
      "Epoch 211/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8481 - accuracy: 0.6320\n",
      "Epoch 212/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8481 - accuracy: 0.6322\n",
      "Epoch 213/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8471 - accuracy: 0.6321\n",
      "Epoch 214/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8468 - accuracy: 0.6321\n",
      "Epoch 215/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8470 - accuracy: 0.6324\n",
      "Epoch 216/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8468 - accuracy: 0.6322\n",
      "Epoch 217/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8461 - accuracy: 0.6325\n",
      "Epoch 218/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8463 - accuracy: 0.6328\n",
      "Epoch 219/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8464 - accuracy: 0.6322\n",
      "Epoch 220/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8460 - accuracy: 0.6326\n",
      "Epoch 221/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8458 - accuracy: 0.6331\n",
      "Epoch 222/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8456 - accuracy: 0.6322\n",
      "Epoch 223/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8456 - accuracy: 0.6326\n",
      "Epoch 224/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8455 - accuracy: 0.6326\n",
      "Epoch 225/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8454 - accuracy: 0.6326\n",
      "Epoch 226/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8455 - accuracy: 0.6337\n",
      "Epoch 227/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8465 - accuracy: 0.6329\n",
      "Epoch 228/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8443 - accuracy: 0.6330\n",
      "Epoch 229/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8448 - accuracy: 0.6335\n",
      "Epoch 230/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8451 - accuracy: 0.6333\n",
      "Epoch 231/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8447 - accuracy: 0.6339\n",
      "Epoch 232/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8446 - accuracy: 0.6338\n",
      "Epoch 233/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8437 - accuracy: 0.6341\n",
      "Epoch 234/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8437 - accuracy: 0.6344\n",
      "Epoch 235/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8459 - accuracy: 0.6335\n",
      "Epoch 236/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8457 - accuracy: 0.6335\n",
      "Epoch 237/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8435 - accuracy: 0.6341\n",
      "Epoch 238/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8441 - accuracy: 0.6339\n",
      "Epoch 239/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8447 - accuracy: 0.6334\n",
      "Epoch 240/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8442 - accuracy: 0.6338\n",
      "Epoch 241/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8435 - accuracy: 0.6342\n",
      "Epoch 242/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8434 - accuracy: 0.6348\n",
      "Epoch 243/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8430 - accuracy: 0.6338\n",
      "Epoch 244/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8439 - accuracy: 0.6338\n",
      "Epoch 245/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8425 - accuracy: 0.6341\n",
      "Epoch 246/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8424 - accuracy: 0.6351\n",
      "Epoch 247/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8428 - accuracy: 0.6336\n",
      "Epoch 248/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8420 - accuracy: 0.6341\n",
      "Epoch 249/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8417 - accuracy: 0.6348\n",
      "Epoch 250/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8417 - accuracy: 0.6347\n",
      "Epoch 251/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8424 - accuracy: 0.6345\n",
      "Epoch 252/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8415 - accuracy: 0.6353\n",
      "Epoch 253/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8423 - accuracy: 0.6346\n",
      "Epoch 254/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8413 - accuracy: 0.6350\n",
      "Epoch 255/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8411 - accuracy: 0.6349\n",
      "Epoch 256/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8409 - accuracy: 0.6354\n",
      "Epoch 257/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8410 - accuracy: 0.6350\n",
      "Epoch 258/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8409 - accuracy: 0.6350\n",
      "Epoch 259/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8403 - accuracy: 0.6346\n",
      "Epoch 260/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8403 - accuracy: 0.6353\n",
      "Epoch 261/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8400 - accuracy: 0.6353\n",
      "Epoch 262/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8398 - accuracy: 0.6355\n",
      "Epoch 263/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8410 - accuracy: 0.6348\n",
      "Epoch 264/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8408 - accuracy: 0.6359\n",
      "Epoch 265/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8401 - accuracy: 0.6355\n",
      "Epoch 266/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8398 - accuracy: 0.6351\n",
      "Epoch 267/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8394 - accuracy: 0.6356\n",
      "Epoch 268/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8396 - accuracy: 0.6352\n",
      "Epoch 269/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8398 - accuracy: 0.6358\n",
      "Epoch 270/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8399 - accuracy: 0.6352\n",
      "Epoch 271/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8389 - accuracy: 0.6362\n",
      "Epoch 272/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8390 - accuracy: 0.6356\n",
      "Epoch 273/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8393 - accuracy: 0.6357\n",
      "Epoch 274/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8394 - accuracy: 0.6354\n",
      "Epoch 275/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8385 - accuracy: 0.6368\n",
      "Epoch 276/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8386 - accuracy: 0.6359\n",
      "Epoch 277/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8384 - accuracy: 0.6362\n",
      "Epoch 278/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8382 - accuracy: 0.6360\n",
      "Epoch 279/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8378 - accuracy: 0.6358\n",
      "Epoch 280/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8387 - accuracy: 0.6358\n",
      "Epoch 281/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8380 - accuracy: 0.6363\n",
      "Epoch 282/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8382 - accuracy: 0.6362\n",
      "Epoch 283/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8380 - accuracy: 0.6371\n",
      "Epoch 284/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8376 - accuracy: 0.6356\n",
      "Epoch 285/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8375 - accuracy: 0.6367\n",
      "Epoch 286/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8401 - accuracy: 0.6359\n",
      "Epoch 287/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8378 - accuracy: 0.6371\n",
      "Epoch 288/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8377 - accuracy: 0.6370\n",
      "Epoch 289/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8383 - accuracy: 0.6364\n",
      "Epoch 290/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8374 - accuracy: 0.6363\n",
      "Epoch 291/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8369 - accuracy: 0.6368\n",
      "Epoch 292/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8375 - accuracy: 0.6364\n",
      "Epoch 293/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8364 - accuracy: 0.6372\n",
      "Epoch 294/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8363 - accuracy: 0.6373\n",
      "Epoch 295/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8366 - accuracy: 0.6370\n",
      "Epoch 296/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8363 - accuracy: 0.6362\n",
      "Epoch 297/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8375 - accuracy: 0.6370\n",
      "Epoch 298/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8366 - accuracy: 0.6373\n",
      "Epoch 299/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8361 - accuracy: 0.6369\n",
      "Epoch 300/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8364 - accuracy: 0.6374\n",
      "Epoch 301/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8363 - accuracy: 0.6381\n",
      "Epoch 302/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8358 - accuracy: 0.6379\n",
      "Epoch 303/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8361 - accuracy: 0.6375\n",
      "Epoch 304/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8360 - accuracy: 0.6376\n",
      "Epoch 305/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8354 - accuracy: 0.6379\n",
      "Epoch 306/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8352 - accuracy: 0.6384\n",
      "Epoch 307/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8345 - accuracy: 0.6374\n",
      "Epoch 308/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8353 - accuracy: 0.6374\n",
      "Epoch 309/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8354 - accuracy: 0.6373\n",
      "Epoch 310/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8355 - accuracy: 0.6377\n",
      "Epoch 311/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8356 - accuracy: 0.6375\n",
      "Epoch 312/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8355 - accuracy: 0.6375\n",
      "Epoch 313/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8344 - accuracy: 0.6380\n",
      "Epoch 314/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8354 - accuracy: 0.6381\n",
      "Epoch 315/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8377 - accuracy: 0.6373\n",
      "Epoch 316/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8359 - accuracy: 0.6375\n",
      "Epoch 317/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8347 - accuracy: 0.6383\n",
      "Epoch 318/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8341 - accuracy: 0.6378\n",
      "Epoch 319/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8340 - accuracy: 0.6380\n",
      "Epoch 320/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8347 - accuracy: 0.6373\n",
      "Epoch 321/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8356 - accuracy: 0.6376\n",
      "Epoch 322/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8346 - accuracy: 0.6371\n",
      "Epoch 323/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8345 - accuracy: 0.6381\n",
      "Epoch 324/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8334 - accuracy: 0.6388\n",
      "Epoch 325/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8340 - accuracy: 0.6384\n",
      "Epoch 326/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8342 - accuracy: 0.6393\n",
      "Epoch 327/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8338 - accuracy: 0.6380\n",
      "Epoch 328/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8331 - accuracy: 0.6385\n",
      "Epoch 329/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8332 - accuracy: 0.6390\n",
      "Epoch 330/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8332 - accuracy: 0.6383\n",
      "Epoch 331/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8335 - accuracy: 0.6388\n",
      "Epoch 332/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8330 - accuracy: 0.6389\n",
      "Epoch 333/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8339 - accuracy: 0.6386\n",
      "Epoch 334/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8337 - accuracy: 0.6376\n",
      "Epoch 335/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8330 - accuracy: 0.6391\n",
      "Epoch 336/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8333 - accuracy: 0.6385\n",
      "Epoch 337/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8326 - accuracy: 0.6385\n",
      "Epoch 338/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8331 - accuracy: 0.6393\n",
      "Epoch 339/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8332 - accuracy: 0.6389\n",
      "Epoch 340/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8323 - accuracy: 0.6391\n",
      "Epoch 341/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8335 - accuracy: 0.6384\n",
      "Epoch 342/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8325 - accuracy: 0.6390\n",
      "Epoch 343/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8327 - accuracy: 0.6389\n",
      "Epoch 344/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8324 - accuracy: 0.6399\n",
      "Epoch 345/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8326 - accuracy: 0.6391\n",
      "Epoch 346/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8327 - accuracy: 0.6388\n",
      "Epoch 347/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8328 - accuracy: 0.6386\n",
      "Epoch 348/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8321 - accuracy: 0.6389\n",
      "Epoch 349/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8321 - accuracy: 0.6388\n",
      "Epoch 350/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8320 - accuracy: 0.6393\n",
      "Epoch 351/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8318 - accuracy: 0.6394\n",
      "Epoch 352/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8321 - accuracy: 0.6387\n",
      "Epoch 353/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8315 - accuracy: 0.6393\n",
      "Epoch 354/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8309 - accuracy: 0.6393\n",
      "Epoch 355/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8313 - accuracy: 0.6396\n",
      "Epoch 356/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8314 - accuracy: 0.6393\n",
      "Epoch 357/400\n",
      "78093/78093 [==============================] - 2s 26us/step - loss: 0.8314 - accuracy: 0.6394\n",
      "Epoch 358/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8318 - accuracy: 0.6393\n",
      "Epoch 359/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8305 - accuracy: 0.6399\n",
      "Epoch 360/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8314 - accuracy: 0.6397\n",
      "Epoch 361/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8310 - accuracy: 0.6392\n",
      "Epoch 362/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8306 - accuracy: 0.6395\n",
      "Epoch 363/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8307 - accuracy: 0.6401\n",
      "Epoch 364/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8304 - accuracy: 0.6398\n",
      "Epoch 365/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8310 - accuracy: 0.6399\n",
      "Epoch 366/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8301 - accuracy: 0.6402\n",
      "Epoch 367/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8299 - accuracy: 0.6402\n",
      "Epoch 368/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8304 - accuracy: 0.6398\n",
      "Epoch 369/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8304 - accuracy: 0.6396\n",
      "Epoch 370/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8301 - accuracy: 0.6400\n",
      "Epoch 371/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8310 - accuracy: 0.6390\n",
      "Epoch 372/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8315 - accuracy: 0.6390\n",
      "Epoch 373/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8300 - accuracy: 0.6404\n",
      "Epoch 374/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8297 - accuracy: 0.6405\n",
      "Epoch 375/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8300 - accuracy: 0.6405\n",
      "Epoch 376/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8294 - accuracy: 0.6398\n",
      "Epoch 377/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8297 - accuracy: 0.6401\n",
      "Epoch 378/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8299 - accuracy: 0.6400\n",
      "Epoch 379/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8309 - accuracy: 0.6397\n",
      "Epoch 380/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8294 - accuracy: 0.6402\n",
      "Epoch 381/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8296 - accuracy: 0.6398\n",
      "Epoch 382/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8289 - accuracy: 0.6410\n",
      "Epoch 383/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8294 - accuracy: 0.6415\n",
      "Epoch 384/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8292 - accuracy: 0.6401\n",
      "Epoch 385/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8295 - accuracy: 0.6406\n",
      "Epoch 386/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8290 - accuracy: 0.6399\n",
      "Epoch 387/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8295 - accuracy: 0.6394\n",
      "Epoch 388/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8282 - accuracy: 0.6407\n",
      "Epoch 389/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8281 - accuracy: 0.6407\n",
      "Epoch 390/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8286 - accuracy: 0.6412\n",
      "Epoch 391/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8296 - accuracy: 0.6409\n",
      "Epoch 392/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8288 - accuracy: 0.6398\n",
      "Epoch 393/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8281 - accuracy: 0.6413\n",
      "Epoch 394/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8293 - accuracy: 0.6393\n",
      "Epoch 395/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8276 - accuracy: 0.6409\n",
      "Epoch 396/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8279 - accuracy: 0.6411\n",
      "Epoch 397/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8284 - accuracy: 0.6405\n",
      "Epoch 398/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8275 - accuracy: 0.6409\n",
      "Epoch 399/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8276 - accuracy: 0.6417\n",
      "Epoch 400/400\n",
      "78093/78093 [==============================] - 2s 25us/step - loss: 0.8282 - accuracy: 0.6412\n",
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history =classifier.fit(X, y, epochs = 400, batch_size = 2048)\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc ='upper left')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with mined data/ does not include term to term data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('model final test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplication process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20181 [00:00<?, ?it/s]/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "100%|██████████| 20181/20181 [00:28<00:00, 715.97it/s]\n"
     ]
    }
   ],
   "source": [
    "to_one = []\n",
    "for i in tqdm(ffs['SubjectID'].unique()):\n",
    "    x = groups.get_group(i)\n",
    "    x['Min GPA']= x['Term GPA'].min()\n",
    "    x['Number of Majors'] = x['Ps1 Major1 Code'].nunique()\n",
    "    x['Hardest Semester']= np.argmin(x['Term GPA'])\n",
    "    to_one.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat(to_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Cumul GPA</th>\n",
       "      <th>Term Transfer Hrs</th>\n",
       "      <th>Major</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Citizen Country Name</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Min GPA</th>\n",
       "      <th>Number of Majors</th>\n",
       "      <th>Hardest Semester</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172846340</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175397669</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>175397669</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ECO</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>175397669</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNC</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>175397669</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PSC</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397024</th>\n",
       "      <td>255137993</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397026</th>\n",
       "      <td>255137993</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397027</th>\n",
       "      <td>255137993</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397029</th>\n",
       "      <td>255461372</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PHY</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397030</th>\n",
       "      <td>255461372</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PHY</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226717 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SubjectID  Cumul GPA  Term Transfer Hrs Major Gender  \\\n",
       "1       172846340       2.70                1.0   PSC      F   \n",
       "4       175397669       2.33                1.0   PSC      M   \n",
       "5       175397669       2.33                1.0   ECO      M   \n",
       "7       175397669       2.33                1.0   UNC      M   \n",
       "9       175397669       2.00                0.0   PSC      M   \n",
       "...           ...        ...                ...   ...    ...   \n",
       "397024  255137993       3.33                0.0    ME      M   \n",
       "397026  255137993       3.40                1.0    ME      M   \n",
       "397027  255137993       3.48                0.0    ME      M   \n",
       "397029  255461372       3.00                1.0   PHY      F   \n",
       "397030  255461372       2.43                0.0   PHY      F   \n",
       "\n",
       "       Citizen Country Name Classification  Min GPA  Number of Majors  \\\n",
       "1                         1              3     3.30                 1   \n",
       "4                         1              0     1.13                 3   \n",
       "5                         1              0     1.13                 3   \n",
       "7                         1              0     1.13                 3   \n",
       "9                         1              0     1.13                 3   \n",
       "...                     ...            ...      ...               ...   \n",
       "397024                    0              3     2.90                 1   \n",
       "397026                    0              3     2.90                 1   \n",
       "397027                    0              3     2.90                 1   \n",
       "397029                    1              0     0.70                 1   \n",
       "397030                    1              0     0.70                 1   \n",
       "\n",
       "        Hardest Semester  \n",
       "1                      0  \n",
       "4                     10  \n",
       "5                     10  \n",
       "7                     10  \n",
       "9                     10  \n",
       "...                  ...  \n",
       "397024                 0  \n",
       "397026                 0  \n",
       "397027                 0  \n",
       "397029                 1  \n",
       "397030                 1  \n",
       "\n",
       "[226717 rows x 10 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same labeling process as the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Classification']=='N', 'Classification']=3\n",
    "final.loc[final['Classification']=='NT', 'Classification']=2\n",
    "final.loc[final['Classification']=='TP', 'Classification']=1\n",
    "final.loc[final['Classification']=='NG', 'Classification']=0\n",
    "final.loc[final['Citizen Country Name']!='USA', 'Citizen Country Name']=0\n",
    "final.loc[final['Citizen Country Name']=='USA', 'Citizen Country Name']=1\n",
    "final.loc[final['Term Transfer Hrs']!=0, 'Term Transfer Hrs']=1\n",
    "final.loc[final['Term Transfer Hrs']==0, 'Term Transfer Hrs']=0\n",
    "final = final.drop(['Repeated Flag','Year Term ID_x', 'Ps1 Acad Standing Desc', 'Ps1 Major2 Code','Term GPA'], axis =1)\n",
    "final= final.rename(columns={\"Ps1 Major1 Code\": \"Major\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "final =final.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keeping the final GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = multiprocessing.cpu_count()\n",
    "chunk_size = int(final.shape[0]/num_processes)\n",
    "chunks = [final.loc[final.index[i:i + chunk_size]] for i in range(0, final.shape[0], chunk_size)]\n",
    "pool = multiprocessing.Pool(processes=num_processes)\n",
    "result = pool.map(last_gpa, chunks)\n",
    "results = pd.concat(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_gpa(df):\n",
    "    for i in df['SubjectID'].unique():\n",
    "        df.loc[df['SubjectID']==i, 'Cumul GPA']= df.loc[df['SubjectID']==i]['Cumul GPA'].iloc[-1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = results.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.drop(['Term Transfer Hrs', 'Hardest Semester'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Cumul GPA</th>\n",
       "      <th>Major</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Citizen Country Name</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Min GPA</th>\n",
       "      <th>Number of Majors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172846340</td>\n",
       "      <td>2.70</td>\n",
       "      <td>PSC</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175397669</td>\n",
       "      <td>2.07</td>\n",
       "      <td>PSC</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>175397669</td>\n",
       "      <td>2.07</td>\n",
       "      <td>ECO</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>175397669</td>\n",
       "      <td>2.07</td>\n",
       "      <td>UNC</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>175693463</td>\n",
       "      <td>3.02</td>\n",
       "      <td>PSY</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396973</th>\n",
       "      <td>254575592</td>\n",
       "      <td>2.79</td>\n",
       "      <td>CSC</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397012</th>\n",
       "      <td>254613473</td>\n",
       "      <td>3.08</td>\n",
       "      <td>MST</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397021</th>\n",
       "      <td>255137993</td>\n",
       "      <td>3.14</td>\n",
       "      <td>ME</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397024</th>\n",
       "      <td>255137993</td>\n",
       "      <td>3.48</td>\n",
       "      <td>ME</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397029</th>\n",
       "      <td>255461372</td>\n",
       "      <td>2.43</td>\n",
       "      <td>PHY</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34059 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SubjectID  Cumul GPA Major Gender Citizen Country Name Classification  \\\n",
       "1       172846340       2.70   PSC      F                    1              3   \n",
       "4       175397669       2.07   PSC      M                    1              0   \n",
       "5       175397669       2.07   ECO      M                    1              0   \n",
       "7       175397669       2.07   UNC      M                    1              0   \n",
       "59      175693463       3.02   PSY      F                    1              3   \n",
       "...           ...        ...   ...    ...                  ...            ...   \n",
       "396973  254575592       2.79   CSC      F                    0              3   \n",
       "397012  254613473       3.08   MST      F                    0              2   \n",
       "397021  255137993       3.14    ME      M                    0              3   \n",
       "397024  255137993       3.48    ME      M                    0              3   \n",
       "397029  255461372       2.43   PHY      F                    1              0   \n",
       "\n",
       "        Min GPA  Number of Majors  \n",
       "1          3.30                 1  \n",
       "4          1.13                 3  \n",
       "5          1.13                 3  \n",
       "7          1.13                 3  \n",
       "59         2.65                 2  \n",
       "...         ...               ...  \n",
       "396973     1.35                 3  \n",
       "397012     2.00                 1  \n",
       "397021     2.90                 1  \n",
       "397024     2.90                 1  \n",
       "397029     0.70                 1  \n",
       "\n",
       "[34059 rows x 8 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one = final.drop(['Classification'], axis =1)\n",
    "y_one = final['Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one = pd.get_dummies(data = X_one, columns= ['Major', 'Gender'],  dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one = pd.get_dummies(data = y_one, columns = ['Classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_one.columns:\n",
    "    X_one[i]= X_one[i]/X_one[i].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34059"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0000    2729\n",
       "0.7500     778\n",
       "0.5000     563\n",
       "0.8325     507\n",
       "0.7950     450\n",
       "          ... \n",
       "0.0950       1\n",
       "0.1400       1\n",
       "0.2275       1\n",
       "0.1025       1\n",
       "0.0200       1\n",
       "Name: Min GPA, Length: 367, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_one['Min GPA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split and learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train,y_test = train_test_split(X_one,y_one,test_size = .10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=106, units=128, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=32, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(activation= 'relu', input_dim = 106, units = 54, init = 'uniform'))\n",
    "classifier.add(Dense(activation= 'relu', units = 40, init = 'uniform'))\n",
    "classifier.add(Dense(activation= 'relu', units = 32, init = 'uniform'))\n",
    "classifier.add(Dense(activation= 'relu', units = 16, init = 'uniform'))\n",
    "classifier.add(Dense(activation= 'softmax', units = 4, init = 'uniform'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(activation= 'relu', input_dim = 106, units = 54, init = 'uniform'))\n",
    "    classifier.add(Dense(activation= 'relu', units = 40, init = 'uniform'))\n",
    "    classifier.add(Dense(activation= 'relu', units = 32, init = 'uniform'))\n",
    "    classifier.add(Dense(activation= 'relu', units = 16, init = 'uniform'))\n",
    "    classifier.add(Dense(activation= 'softmax', units = 4, init = 'uniform'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=106, units=54, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=40, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=32, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "27247/27247 [==============================] - 1s 26us/step - loss: 1.3829 - accuracy: 0.5336\n",
      "Epoch 2/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 1.3742 - accuracy: 0.5585\n",
      "Epoch 3/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 1.3612 - accuracy: 0.5585\n",
      "Epoch 4/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 1.3305 - accuracy: 0.5585\n",
      "Epoch 5/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 1.2444 - accuracy: 0.5585\n",
      "Epoch 6/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 1.0793 - accuracy: 0.5585\n",
      "Epoch 7/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 1.0038 - accuracy: 0.5585\n",
      "Epoch 8/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9904 - accuracy: 0.5585\n",
      "Epoch 9/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9787 - accuracy: 0.5585\n",
      "Epoch 10/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9714 - accuracy: 0.5585\n",
      "Epoch 11/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9680 - accuracy: 0.5585\n",
      "Epoch 12/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9649 - accuracy: 0.5585\n",
      "Epoch 13/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9627 - accuracy: 0.5585\n",
      "Epoch 14/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9606 - accuracy: 0.5585\n",
      "Epoch 15/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9585 - accuracy: 0.5585\n",
      "Epoch 16/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9565 - accuracy: 0.5585\n",
      "Epoch 17/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9543 - accuracy: 0.5585\n",
      "Epoch 18/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9521 - accuracy: 0.5585\n",
      "Epoch 19/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9499 - accuracy: 0.5585\n",
      "Epoch 20/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9477 - accuracy: 0.5585\n",
      "Epoch 21/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9452 - accuracy: 0.5585\n",
      "Epoch 22/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9431 - accuracy: 0.5585\n",
      "Epoch 23/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9411 - accuracy: 0.5585\n",
      "Epoch 24/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9392 - accuracy: 0.5588\n",
      "Epoch 25/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9374 - accuracy: 0.5592\n",
      "Epoch 26/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9360 - accuracy: 0.5600\n",
      "Epoch 27/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9348 - accuracy: 0.5610\n",
      "Epoch 28/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9329 - accuracy: 0.5626\n",
      "Epoch 29/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9314 - accuracy: 0.5637\n",
      "Epoch 30/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9296 - accuracy: 0.5664\n",
      "Epoch 31/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9275 - accuracy: 0.5705\n",
      "Epoch 32/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9257 - accuracy: 0.5737\n",
      "Epoch 33/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9233 - accuracy: 0.5786\n",
      "Epoch 34/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9215 - accuracy: 0.5811\n",
      "Epoch 35/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9190 - accuracy: 0.5834\n",
      "Epoch 36/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9171 - accuracy: 0.5851\n",
      "Epoch 37/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9157 - accuracy: 0.5862\n",
      "Epoch 38/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9141 - accuracy: 0.5858\n",
      "Epoch 39/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9126 - accuracy: 0.5861\n",
      "Epoch 40/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9114 - accuracy: 0.5888\n",
      "Epoch 41/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9099 - accuracy: 0.5890\n",
      "Epoch 42/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9083 - accuracy: 0.5899\n",
      "Epoch 43/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9066 - accuracy: 0.5896\n",
      "Epoch 44/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9057 - accuracy: 0.5892\n",
      "Epoch 45/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9040 - accuracy: 0.5933\n",
      "Epoch 46/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9025 - accuracy: 0.5989\n",
      "Epoch 47/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9012 - accuracy: 0.6003\n",
      "Epoch 48/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9001 - accuracy: 0.6000\n",
      "Epoch 49/300\n",
      "27247/27247 [==============================] - 1s 26us/step - loss: 0.8994 - accuracy: 0.6009\n",
      "Epoch 50/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8984 - accuracy: 0.6014\n",
      "Epoch 51/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8967 - accuracy: 0.6030\n",
      "Epoch 52/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8958 - accuracy: 0.6030\n",
      "Epoch 53/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8951 - accuracy: 0.6020\n",
      "Epoch 54/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8937 - accuracy: 0.6034\n",
      "Epoch 55/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8933 - accuracy: 0.6025\n",
      "Epoch 56/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8925 - accuracy: 0.6011\n",
      "Epoch 57/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8914 - accuracy: 0.6023\n",
      "Epoch 58/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8902 - accuracy: 0.6018\n",
      "Epoch 59/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8898 - accuracy: 0.6011\n",
      "Epoch 60/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8896 - accuracy: 0.6022\n",
      "Epoch 61/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8883 - accuracy: 0.6021\n",
      "Epoch 62/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8881 - accuracy: 0.6015\n",
      "Epoch 63/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8882 - accuracy: 0.6020\n",
      "Epoch 64/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8878 - accuracy: 0.6000\n",
      "Epoch 65/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8868 - accuracy: 0.6016\n",
      "Epoch 66/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8856 - accuracy: 0.6016\n",
      "Epoch 67/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8859 - accuracy: 0.6016\n",
      "Epoch 68/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8846 - accuracy: 0.6016\n",
      "Epoch 69/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8839 - accuracy: 0.6021\n",
      "Epoch 70/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8838 - accuracy: 0.6007\n",
      "Epoch 71/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8830 - accuracy: 0.6027\n",
      "Epoch 72/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8834 - accuracy: 0.6004\n",
      "Epoch 73/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8832 - accuracy: 0.6011\n",
      "Epoch 74/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8824 - accuracy: 0.6004\n",
      "Epoch 75/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8819 - accuracy: 0.6004\n",
      "Epoch 76/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8809 - accuracy: 0.6021\n",
      "Epoch 77/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8812 - accuracy: 0.6002\n",
      "Epoch 78/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8811 - accuracy: 0.6009\n",
      "Epoch 79/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8805 - accuracy: 0.6016\n",
      "Epoch 80/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8797 - accuracy: 0.6020\n",
      "Epoch 81/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8798 - accuracy: 0.6003\n",
      "Epoch 82/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8807 - accuracy: 0.5998\n",
      "Epoch 83/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8801 - accuracy: 0.6001\n",
      "Epoch 84/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8784 - accuracy: 0.6011\n",
      "Epoch 85/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8781 - accuracy: 0.6010\n",
      "Epoch 86/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8777 - accuracy: 0.6005\n",
      "Epoch 87/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8771 - accuracy: 0.6009\n",
      "Epoch 88/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8769 - accuracy: 0.6011\n",
      "Epoch 89/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8765 - accuracy: 0.6017\n",
      "Epoch 90/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8762 - accuracy: 0.6024\n",
      "Epoch 91/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8758 - accuracy: 0.6014\n",
      "Epoch 92/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8763 - accuracy: 0.6009\n",
      "Epoch 93/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8751 - accuracy: 0.6020\n",
      "Epoch 94/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8746 - accuracy: 0.6028\n",
      "Epoch 95/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8750 - accuracy: 0.6008\n",
      "Epoch 96/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8738 - accuracy: 0.6013\n",
      "Epoch 97/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8733 - accuracy: 0.6017\n",
      "Epoch 98/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8729 - accuracy: 0.6022\n",
      "Epoch 99/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8732 - accuracy: 0.6014\n",
      "Epoch 100/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8724 - accuracy: 0.6022\n",
      "Epoch 101/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8717 - accuracy: 0.6026\n",
      "Epoch 102/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8713 - accuracy: 0.6020\n",
      "Epoch 103/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8707 - accuracy: 0.6024\n",
      "Epoch 104/300\n",
      "27247/27247 [==============================] - 1s 26us/step - loss: 0.8703 - accuracy: 0.6026\n",
      "Epoch 105/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8700 - accuracy: 0.6029\n",
      "Epoch 106/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8689 - accuracy: 0.6030\n",
      "Epoch 107/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8683 - accuracy: 0.6035\n",
      "Epoch 108/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8675 - accuracy: 0.6037\n",
      "Epoch 109/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8666 - accuracy: 0.6044\n",
      "Epoch 110/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8656 - accuracy: 0.6055\n",
      "Epoch 111/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8645 - accuracy: 0.6058\n",
      "Epoch 112/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8629 - accuracy: 0.6059\n",
      "Epoch 113/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8613 - accuracy: 0.6081\n",
      "Epoch 114/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8587 - accuracy: 0.6107\n",
      "Epoch 115/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8564 - accuracy: 0.6110\n",
      "Epoch 116/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8530 - accuracy: 0.6143\n",
      "Epoch 117/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8503 - accuracy: 0.6170\n",
      "Epoch 118/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8470 - accuracy: 0.6200\n",
      "Epoch 119/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8423 - accuracy: 0.6236\n",
      "Epoch 120/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8371 - accuracy: 0.6238\n",
      "Epoch 121/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8326 - accuracy: 0.6256\n",
      "Epoch 122/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8280 - accuracy: 0.6261\n",
      "Epoch 123/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8241 - accuracy: 0.6248\n",
      "Epoch 124/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8201 - accuracy: 0.6249\n",
      "Epoch 125/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8153 - accuracy: 0.6287\n",
      "Epoch 126/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8129 - accuracy: 0.6288\n",
      "Epoch 127/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8104 - accuracy: 0.6301\n",
      "Epoch 128/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8077 - accuracy: 0.6303\n",
      "Epoch 129/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8068 - accuracy: 0.6294\n",
      "Epoch 130/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8062 - accuracy: 0.6301\n",
      "Epoch 131/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8031 - accuracy: 0.6304\n",
      "Epoch 132/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8024 - accuracy: 0.6299\n",
      "Epoch 133/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8024 - accuracy: 0.6317\n",
      "Epoch 134/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8004 - accuracy: 0.6320\n",
      "Epoch 135/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7992 - accuracy: 0.6321\n",
      "Epoch 136/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7988 - accuracy: 0.6315\n",
      "Epoch 137/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7980 - accuracy: 0.6320\n",
      "Epoch 138/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7982 - accuracy: 0.6331\n",
      "Epoch 139/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7969 - accuracy: 0.6329\n",
      "Epoch 140/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7955 - accuracy: 0.6326\n",
      "Epoch 141/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7956 - accuracy: 0.6320\n",
      "Epoch 142/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7961 - accuracy: 0.6326\n",
      "Epoch 143/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7952 - accuracy: 0.6318\n",
      "Epoch 144/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7940 - accuracy: 0.6330\n",
      "Epoch 145/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7935 - accuracy: 0.6327\n",
      "Epoch 146/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7934 - accuracy: 0.6339\n",
      "Epoch 147/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7922 - accuracy: 0.6322\n",
      "Epoch 148/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7914 - accuracy: 0.6327\n",
      "Epoch 149/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7920 - accuracy: 0.6333\n",
      "Epoch 150/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7915 - accuracy: 0.6326\n",
      "Epoch 151/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7908 - accuracy: 0.6346\n",
      "Epoch 152/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7916 - accuracy: 0.6335\n",
      "Epoch 153/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7903 - accuracy: 0.6343\n",
      "Epoch 154/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7894 - accuracy: 0.6349\n",
      "Epoch 155/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7896 - accuracy: 0.6336\n",
      "Epoch 156/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7902 - accuracy: 0.6340\n",
      "Epoch 157/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7902 - accuracy: 0.6344\n",
      "Epoch 158/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7884 - accuracy: 0.6343\n",
      "Epoch 159/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7881 - accuracy: 0.6356\n",
      "Epoch 160/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7876 - accuracy: 0.6351\n",
      "Epoch 161/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7881 - accuracy: 0.6353\n",
      "Epoch 162/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7887 - accuracy: 0.6356\n",
      "Epoch 163/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7869 - accuracy: 0.6365\n",
      "Epoch 164/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7870 - accuracy: 0.6347\n",
      "Epoch 165/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7868 - accuracy: 0.6360\n",
      "Epoch 166/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7868 - accuracy: 0.6361\n",
      "Epoch 167/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7870 - accuracy: 0.6363\n",
      "Epoch 168/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7875 - accuracy: 0.6349\n",
      "Epoch 169/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7860 - accuracy: 0.6374\n",
      "Epoch 170/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7855 - accuracy: 0.6371\n",
      "Epoch 171/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7858 - accuracy: 0.6373\n",
      "Epoch 172/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7859 - accuracy: 0.6372\n",
      "Epoch 173/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7858 - accuracy: 0.6368\n",
      "Epoch 174/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7867 - accuracy: 0.6360\n",
      "Epoch 175/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7858 - accuracy: 0.6379\n",
      "Epoch 176/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7857 - accuracy: 0.6368\n",
      "Epoch 177/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7853 - accuracy: 0.6355\n",
      "Epoch 178/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7852 - accuracy: 0.6368\n",
      "Epoch 179/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7839 - accuracy: 0.6384\n",
      "Epoch 180/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7854 - accuracy: 0.6373\n",
      "Epoch 181/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7855 - accuracy: 0.6370\n",
      "Epoch 182/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7841 - accuracy: 0.6386\n",
      "Epoch 183/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7840 - accuracy: 0.6375\n",
      "Epoch 184/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7849 - accuracy: 0.6383\n",
      "Epoch 185/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7855 - accuracy: 0.6365\n",
      "Epoch 186/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7842 - accuracy: 0.6371\n",
      "Epoch 187/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7840 - accuracy: 0.6368\n",
      "Epoch 188/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7831 - accuracy: 0.6380\n",
      "Epoch 189/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7827 - accuracy: 0.6389\n",
      "Epoch 190/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7830 - accuracy: 0.6389\n",
      "Epoch 191/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7825 - accuracy: 0.6389\n",
      "Epoch 192/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7826 - accuracy: 0.6386\n",
      "Epoch 193/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7826 - accuracy: 0.6389\n",
      "Epoch 194/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7830 - accuracy: 0.6377\n",
      "Epoch 195/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7818 - accuracy: 0.6378\n",
      "Epoch 196/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7815 - accuracy: 0.6387\n",
      "Epoch 197/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7824 - accuracy: 0.6391\n",
      "Epoch 198/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7827 - accuracy: 0.6383\n",
      "Epoch 199/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7853 - accuracy: 0.6369\n",
      "Epoch 200/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7842 - accuracy: 0.6363\n",
      "Epoch 201/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7815 - accuracy: 0.6386\n",
      "Epoch 202/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7817 - accuracy: 0.6376\n",
      "Epoch 203/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7812 - accuracy: 0.6385\n",
      "Epoch 204/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6392\n",
      "Epoch 205/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7819 - accuracy: 0.6386\n",
      "Epoch 206/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7817 - accuracy: 0.6384\n",
      "Epoch 207/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7816 - accuracy: 0.6378\n",
      "Epoch 208/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7819 - accuracy: 0.6374\n",
      "Epoch 209/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7821 - accuracy: 0.6385\n",
      "Epoch 210/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7824 - accuracy: 0.6380\n",
      "Epoch 211/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7814 - accuracy: 0.6386\n",
      "Epoch 212/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7820 - accuracy: 0.6375\n",
      "Epoch 213/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6389\n",
      "Epoch 214/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7808 - accuracy: 0.6382\n",
      "Epoch 215/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7831 - accuracy: 0.6377\n",
      "Epoch 216/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7823 - accuracy: 0.6376\n",
      "Epoch 217/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6395\n",
      "Epoch 218/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7803 - accuracy: 0.6383\n",
      "Epoch 219/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7802 - accuracy: 0.6384\n",
      "Epoch 220/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7801 - accuracy: 0.6385\n",
      "Epoch 221/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7806 - accuracy: 0.6385\n",
      "Epoch 222/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7812 - accuracy: 0.6392\n",
      "Epoch 223/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7825 - accuracy: 0.6377\n",
      "Epoch 224/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7821 - accuracy: 0.6375\n",
      "Epoch 225/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7803 - accuracy: 0.6385\n",
      "Epoch 226/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7791 - accuracy: 0.6395\n",
      "Epoch 227/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7795 - accuracy: 0.6388\n",
      "Epoch 228/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7793 - accuracy: 0.6400\n",
      "Epoch 229/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7793 - accuracy: 0.6392\n",
      "Epoch 230/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7794 - accuracy: 0.6396\n",
      "Epoch 231/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7792 - accuracy: 0.6398\n",
      "Epoch 232/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7797 - accuracy: 0.6390\n",
      "Epoch 233/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7798 - accuracy: 0.6401\n",
      "Epoch 234/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7811 - accuracy: 0.6383\n",
      "Epoch 235/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7807 - accuracy: 0.6388\n",
      "Epoch 236/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7801 - accuracy: 0.6398\n",
      "Epoch 237/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7807 - accuracy: 0.6390\n",
      "Epoch 238/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7799 - accuracy: 0.6390\n",
      "Epoch 239/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6400\n",
      "Epoch 240/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7803 - accuracy: 0.6395\n",
      "Epoch 241/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7801 - accuracy: 0.6395\n",
      "Epoch 242/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7810 - accuracy: 0.6389\n",
      "Epoch 243/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7802 - accuracy: 0.6391\n",
      "Epoch 244/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7786 - accuracy: 0.6396\n",
      "Epoch 245/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7786 - accuracy: 0.6392\n",
      "Epoch 246/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7779 - accuracy: 0.6403\n",
      "Epoch 247/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7786 - accuracy: 0.6387\n",
      "Epoch 248/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7790 - accuracy: 0.6399\n",
      "Epoch 249/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7791 - accuracy: 0.6395\n",
      "Epoch 250/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7801 - accuracy: 0.6397\n",
      "Epoch 251/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7786 - accuracy: 0.6396\n",
      "Epoch 252/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7800 - accuracy: 0.6397\n",
      "Epoch 253/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7786 - accuracy: 0.6408\n",
      "Epoch 254/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7788 - accuracy: 0.6402\n",
      "Epoch 255/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7782 - accuracy: 0.6401\n",
      "Epoch 256/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7779 - accuracy: 0.6396\n",
      "Epoch 257/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7789 - accuracy: 0.6393\n",
      "Epoch 258/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7781 - accuracy: 0.6399\n",
      "Epoch 259/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7782 - accuracy: 0.6408\n",
      "Epoch 260/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7779 - accuracy: 0.6406\n",
      "Epoch 261/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7780 - accuracy: 0.6405\n",
      "Epoch 262/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7778 - accuracy: 0.6400\n",
      "Epoch 263/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7775 - accuracy: 0.6411\n",
      "Epoch 264/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7780 - accuracy: 0.6404\n",
      "Epoch 265/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7777 - accuracy: 0.6406\n",
      "Epoch 266/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7782 - accuracy: 0.6405\n",
      "Epoch 267/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7775 - accuracy: 0.6403\n",
      "Epoch 268/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7772 - accuracy: 0.6405\n",
      "Epoch 269/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7777 - accuracy: 0.6407\n",
      "Epoch 270/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6410\n",
      "Epoch 271/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7777 - accuracy: 0.6401\n",
      "Epoch 272/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7769 - accuracy: 0.6408\n",
      "Epoch 273/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7767 - accuracy: 0.6409\n",
      "Epoch 274/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7769 - accuracy: 0.6405\n",
      "Epoch 275/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7775 - accuracy: 0.6410\n",
      "Epoch 276/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7771 - accuracy: 0.6401\n",
      "Epoch 277/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6397\n",
      "Epoch 278/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7796 - accuracy: 0.6398\n",
      "Epoch 279/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7775 - accuracy: 0.6396\n",
      "Epoch 280/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7767 - accuracy: 0.6402\n",
      "Epoch 281/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7777 - accuracy: 0.6414\n",
      "Epoch 282/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7772 - accuracy: 0.6410\n",
      "Epoch 283/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7768 - accuracy: 0.6408\n",
      "Epoch 284/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7780 - accuracy: 0.6393\n",
      "Epoch 285/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6403\n",
      "Epoch 286/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7768 - accuracy: 0.6409\n",
      "Epoch 287/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7768 - accuracy: 0.6406\n",
      "Epoch 288/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7769 - accuracy: 0.6401\n",
      "Epoch 289/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7786 - accuracy: 0.6406\n",
      "Epoch 290/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7786 - accuracy: 0.6404\n",
      "Epoch 291/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7768 - accuracy: 0.6412\n",
      "Epoch 292/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7763 - accuracy: 0.6401\n",
      "Epoch 293/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7782 - accuracy: 0.6406\n",
      "Epoch 294/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7777 - accuracy: 0.6394\n",
      "Epoch 295/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7778 - accuracy: 0.6408\n",
      "Epoch 296/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7778 - accuracy: 0.6387\n",
      "Epoch 297/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6402\n",
      "Epoch 298/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7761 - accuracy: 0.6411\n",
      "Epoch 299/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7767 - accuracy: 0.6410\n",
      "Epoch 300/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7769 - accuracy: 0.6419\n",
      "6812/6812 [==============================] - 0s 47us/step\n",
      "Model evaluation  [0.852412684063175, 0.6103934049606323]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=106, units=54, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=40, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=32, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "27247/27247 [==============================] - 1s 26us/step - loss: 1.3828 - accuracy: 0.5157\n",
      "Epoch 2/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 1.3737 - accuracy: 0.5555\n",
      "Epoch 3/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 1.3603 - accuracy: 0.5555\n",
      "Epoch 4/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 1.3315 - accuracy: 0.5555\n",
      "Epoch 5/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 1.2531 - accuracy: 0.5555\n",
      "Epoch 6/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 1.0895 - accuracy: 0.5555\n",
      "Epoch 7/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 1.0061 - accuracy: 0.5555\n",
      "Epoch 8/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9978 - accuracy: 0.5555\n",
      "Epoch 9/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9849 - accuracy: 0.5555\n",
      "Epoch 10/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.9798 - accuracy: 0.5555\n",
      "Epoch 11/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9761 - accuracy: 0.5555\n",
      "Epoch 12/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.9736 - accuracy: 0.5555\n",
      "Epoch 13/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9715 - accuracy: 0.5555\n",
      "Epoch 14/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9696 - accuracy: 0.5555\n",
      "Epoch 15/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9675 - accuracy: 0.5555\n",
      "Epoch 16/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9653 - accuracy: 0.5555\n",
      "Epoch 17/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9631 - accuracy: 0.5555\n",
      "Epoch 18/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9607 - accuracy: 0.5555\n",
      "Epoch 19/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9583 - accuracy: 0.5555\n",
      "Epoch 20/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9556 - accuracy: 0.5555\n",
      "Epoch 21/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.9527 - accuracy: 0.5555\n",
      "Epoch 22/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9497 - accuracy: 0.5560\n",
      "Epoch 23/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.9467 - accuracy: 0.5566\n",
      "Epoch 24/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9439 - accuracy: 0.5579\n",
      "Epoch 25/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9413 - accuracy: 0.5605\n",
      "Epoch 26/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.9385 - accuracy: 0.5634\n",
      "Epoch 27/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.9357 - accuracy: 0.5675\n",
      "Epoch 28/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9326 - accuracy: 0.5725\n",
      "Epoch 29/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.9292 - accuracy: 0.5763\n",
      "Epoch 30/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9263 - accuracy: 0.5800\n",
      "Epoch 31/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9232 - accuracy: 0.5820\n",
      "Epoch 32/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9206 - accuracy: 0.5833\n",
      "Epoch 33/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9163 - accuracy: 0.5867\n",
      "Epoch 34/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.9133 - accuracy: 0.5940\n",
      "Epoch 35/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9129 - accuracy: 0.5941\n",
      "Epoch 36/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9075 - accuracy: 0.5974\n",
      "Epoch 37/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.9048 - accuracy: 0.5989\n",
      "Epoch 38/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.9015 - accuracy: 0.6001\n",
      "Epoch 39/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8990 - accuracy: 0.5996\n",
      "Epoch 40/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8965 - accuracy: 0.6008\n",
      "Epoch 41/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8941 - accuracy: 0.5989\n",
      "Epoch 42/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8922 - accuracy: 0.5978\n",
      "Epoch 43/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8898 - accuracy: 0.5978\n",
      "Epoch 44/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8891 - accuracy: 0.5976\n",
      "Epoch 45/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8865 - accuracy: 0.5965\n",
      "Epoch 46/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8844 - accuracy: 0.5963\n",
      "Epoch 47/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8825 - accuracy: 0.5964\n",
      "Epoch 48/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8807 - accuracy: 0.5955\n",
      "Epoch 49/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8808 - accuracy: 0.5957\n",
      "Epoch 50/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8775 - accuracy: 0.5956\n",
      "Epoch 51/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8754 - accuracy: 0.5940\n",
      "Epoch 52/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8735 - accuracy: 0.5945\n",
      "Epoch 53/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8720 - accuracy: 0.5946\n",
      "Epoch 54/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8725 - accuracy: 0.5936\n",
      "Epoch 55/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8692 - accuracy: 0.5930\n",
      "Epoch 56/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8673 - accuracy: 0.5940\n",
      "Epoch 57/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8655 - accuracy: 0.5937\n",
      "Epoch 58/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8639 - accuracy: 0.5946\n",
      "Epoch 59/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8627 - accuracy: 0.5962\n",
      "Epoch 60/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8617 - accuracy: 0.5946\n",
      "Epoch 61/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8601 - accuracy: 0.5958\n",
      "Epoch 62/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8591 - accuracy: 0.5967\n",
      "Epoch 63/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8585 - accuracy: 0.5946\n",
      "Epoch 64/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8568 - accuracy: 0.5972\n",
      "Epoch 65/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8560 - accuracy: 0.5962\n",
      "Epoch 66/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8553 - accuracy: 0.5961\n",
      "Epoch 67/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8556 - accuracy: 0.5958\n",
      "Epoch 68/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8562 - accuracy: 0.5947\n",
      "Epoch 69/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8521 - accuracy: 0.5957\n",
      "Epoch 70/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8514 - accuracy: 0.5964\n",
      "Epoch 71/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8503 - accuracy: 0.5967\n",
      "Epoch 72/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8494 - accuracy: 0.5974\n",
      "Epoch 73/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8490 - accuracy: 0.5969\n",
      "Epoch 74/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8478 - accuracy: 0.5972\n",
      "Epoch 75/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8473 - accuracy: 0.5972\n",
      "Epoch 76/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8458 - accuracy: 0.5971\n",
      "Epoch 77/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8453 - accuracy: 0.5965\n",
      "Epoch 78/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8448 - accuracy: 0.5960\n",
      "Epoch 79/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8434 - accuracy: 0.5964\n",
      "Epoch 80/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8423 - accuracy: 0.5962\n",
      "Epoch 81/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8416 - accuracy: 0.5964\n",
      "Epoch 82/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8418 - accuracy: 0.5954\n",
      "Epoch 83/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8402 - accuracy: 0.5952\n",
      "Epoch 84/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8369 - accuracy: 0.5971\n",
      "Epoch 85/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8324 - accuracy: 0.5991\n",
      "Epoch 86/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8301 - accuracy: 0.5997\n",
      "Epoch 87/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8270 - accuracy: 0.6033\n",
      "Epoch 88/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8256 - accuracy: 0.6058\n",
      "Epoch 89/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8230 - accuracy: 0.6098\n",
      "Epoch 90/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8193 - accuracy: 0.6120\n",
      "Epoch 91/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8169 - accuracy: 0.6168\n",
      "Epoch 92/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8149 - accuracy: 0.6209\n",
      "Epoch 93/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8158 - accuracy: 0.6214\n",
      "Epoch 94/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8124 - accuracy: 0.6237\n",
      "Epoch 95/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8065 - accuracy: 0.6239\n",
      "Epoch 96/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8040 - accuracy: 0.6247\n",
      "Epoch 97/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8023 - accuracy: 0.6263\n",
      "Epoch 98/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.8015 - accuracy: 0.6251\n",
      "Epoch 99/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8003 - accuracy: 0.6256\n",
      "Epoch 100/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7992 - accuracy: 0.6256\n",
      "Epoch 101/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7979 - accuracy: 0.6282\n",
      "Epoch 102/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8003 - accuracy: 0.6284\n",
      "Epoch 103/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8007 - accuracy: 0.6273\n",
      "Epoch 104/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8039 - accuracy: 0.6258\n",
      "Epoch 105/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8000 - accuracy: 0.6281\n",
      "Epoch 106/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7971 - accuracy: 0.6281\n",
      "Epoch 107/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7970 - accuracy: 0.6296\n",
      "Epoch 108/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7948 - accuracy: 0.6308\n",
      "Epoch 109/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7941 - accuracy: 0.6314\n",
      "Epoch 110/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7936 - accuracy: 0.6309\n",
      "Epoch 111/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7932 - accuracy: 0.6322\n",
      "Epoch 112/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7948 - accuracy: 0.6307\n",
      "Epoch 113/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7929 - accuracy: 0.6316\n",
      "Epoch 114/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7918 - accuracy: 0.6314\n",
      "Epoch 115/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7910 - accuracy: 0.6335\n",
      "Epoch 116/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7917 - accuracy: 0.6335\n",
      "Epoch 117/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7927 - accuracy: 0.6318\n",
      "Epoch 118/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7903 - accuracy: 0.6344\n",
      "Epoch 119/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7909 - accuracy: 0.6316\n",
      "Epoch 120/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7907 - accuracy: 0.6330\n",
      "Epoch 121/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7894 - accuracy: 0.6346\n",
      "Epoch 122/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7897 - accuracy: 0.6336\n",
      "Epoch 123/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7898 - accuracy: 0.6348\n",
      "Epoch 124/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7888 - accuracy: 0.6350\n",
      "Epoch 125/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7887 - accuracy: 0.6348\n",
      "Epoch 126/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7882 - accuracy: 0.6353\n",
      "Epoch 127/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7888 - accuracy: 0.6345\n",
      "Epoch 128/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7903 - accuracy: 0.6338\n",
      "Epoch 129/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7899 - accuracy: 0.6332\n",
      "Epoch 130/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7893 - accuracy: 0.6343\n",
      "Epoch 131/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7882 - accuracy: 0.6356\n",
      "Epoch 132/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7880 - accuracy: 0.6345\n",
      "Epoch 133/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7887 - accuracy: 0.6335\n",
      "Epoch 134/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7896 - accuracy: 0.6346\n",
      "Epoch 135/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7891 - accuracy: 0.6348\n",
      "Epoch 136/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7896 - accuracy: 0.6325\n",
      "Epoch 137/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7881 - accuracy: 0.6345\n",
      "Epoch 138/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7873 - accuracy: 0.6350\n",
      "Epoch 139/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7881 - accuracy: 0.6334\n",
      "Epoch 140/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7870 - accuracy: 0.6343\n",
      "Epoch 141/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7864 - accuracy: 0.6365\n",
      "Epoch 142/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7871 - accuracy: 0.6364\n",
      "Epoch 143/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7878 - accuracy: 0.6348\n",
      "Epoch 144/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7879 - accuracy: 0.6338\n",
      "Epoch 145/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7871 - accuracy: 0.6342\n",
      "Epoch 146/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7880 - accuracy: 0.6358\n",
      "Epoch 147/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7869 - accuracy: 0.6367\n",
      "Epoch 148/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7859 - accuracy: 0.6357\n",
      "Epoch 149/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7853 - accuracy: 0.6365\n",
      "Epoch 150/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7858 - accuracy: 0.6361\n",
      "Epoch 151/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7854 - accuracy: 0.6357\n",
      "Epoch 152/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7853 - accuracy: 0.6372\n",
      "Epoch 153/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7855 - accuracy: 0.6368\n",
      "Epoch 154/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7850 - accuracy: 0.6362\n",
      "Epoch 155/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7852 - accuracy: 0.6359\n",
      "Epoch 156/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7846 - accuracy: 0.6370\n",
      "Epoch 157/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7847 - accuracy: 0.6364\n",
      "Epoch 158/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7845 - accuracy: 0.6364\n",
      "Epoch 159/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7854 - accuracy: 0.6351\n",
      "Epoch 160/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7858 - accuracy: 0.6364\n",
      "Epoch 161/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7841 - accuracy: 0.6360\n",
      "Epoch 162/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7838 - accuracy: 0.6360\n",
      "Epoch 163/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7839 - accuracy: 0.6381\n",
      "Epoch 164/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7836 - accuracy: 0.6363\n",
      "Epoch 165/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7841 - accuracy: 0.6375\n",
      "Epoch 166/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7841 - accuracy: 0.6375\n",
      "Epoch 167/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7834 - accuracy: 0.6371\n",
      "Epoch 168/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7837 - accuracy: 0.6375\n",
      "Epoch 169/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7833 - accuracy: 0.6378\n",
      "Epoch 170/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7834 - accuracy: 0.6383\n",
      "Epoch 171/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7834 - accuracy: 0.6374\n",
      "Epoch 172/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7834 - accuracy: 0.6378\n",
      "Epoch 173/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7827 - accuracy: 0.6379\n",
      "Epoch 174/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7826 - accuracy: 0.6378\n",
      "Epoch 175/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7823 - accuracy: 0.6371\n",
      "Epoch 176/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7827 - accuracy: 0.6377\n",
      "Epoch 177/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7845 - accuracy: 0.6364\n",
      "Epoch 178/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7836 - accuracy: 0.6374\n",
      "Epoch 179/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7829 - accuracy: 0.6372\n",
      "Epoch 180/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7838 - accuracy: 0.6375\n",
      "Epoch 181/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7828 - accuracy: 0.6380\n",
      "Epoch 182/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7832 - accuracy: 0.6371\n",
      "Epoch 183/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7829 - accuracy: 0.6375\n",
      "Epoch 184/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7829 - accuracy: 0.6380\n",
      "Epoch 185/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7829 - accuracy: 0.6374\n",
      "Epoch 186/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7824 - accuracy: 0.6396\n",
      "Epoch 187/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7820 - accuracy: 0.6375\n",
      "Epoch 188/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7819 - accuracy: 0.6377\n",
      "Epoch 189/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7837 - accuracy: 0.6385\n",
      "Epoch 190/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7835 - accuracy: 0.6369\n",
      "Epoch 191/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7820 - accuracy: 0.6386\n",
      "Epoch 192/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7832 - accuracy: 0.6371\n",
      "Epoch 193/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7824 - accuracy: 0.6367\n",
      "Epoch 194/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7814 - accuracy: 0.6383\n",
      "Epoch 195/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7811 - accuracy: 0.6384\n",
      "Epoch 196/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7809 - accuracy: 0.6371\n",
      "Epoch 197/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7819 - accuracy: 0.6373\n",
      "Epoch 198/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7817 - accuracy: 0.6378\n",
      "Epoch 199/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7806 - accuracy: 0.6390\n",
      "Epoch 200/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7803 - accuracy: 0.6392\n",
      "Epoch 201/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7809 - accuracy: 0.6374\n",
      "Epoch 202/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7811 - accuracy: 0.6385\n",
      "Epoch 203/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7805 - accuracy: 0.6386\n",
      "Epoch 204/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7807 - accuracy: 0.6385\n",
      "Epoch 205/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7805 - accuracy: 0.6378\n",
      "Epoch 206/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7813 - accuracy: 0.6386\n",
      "Epoch 207/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7810 - accuracy: 0.6378\n",
      "Epoch 208/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7799 - accuracy: 0.6385\n",
      "Epoch 209/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7800 - accuracy: 0.6385\n",
      "Epoch 210/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7826 - accuracy: 0.6369\n",
      "Epoch 211/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7837 - accuracy: 0.6370\n",
      "Epoch 212/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6388\n",
      "Epoch 213/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7813 - accuracy: 0.6372\n",
      "Epoch 214/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7823 - accuracy: 0.6376\n",
      "Epoch 215/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7821 - accuracy: 0.6369\n",
      "Epoch 216/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7816 - accuracy: 0.6383\n",
      "Epoch 217/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7808 - accuracy: 0.6399\n",
      "Epoch 218/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7801 - accuracy: 0.6382\n",
      "Epoch 219/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7796 - accuracy: 0.6388\n",
      "Epoch 220/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7800 - accuracy: 0.6389\n",
      "Epoch 221/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7797 - accuracy: 0.6382\n",
      "Epoch 222/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7812 - accuracy: 0.6392\n",
      "Epoch 223/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7800 - accuracy: 0.6388\n",
      "Epoch 224/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7809 - accuracy: 0.6374\n",
      "Epoch 225/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7801 - accuracy: 0.6380\n",
      "Epoch 226/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7796 - accuracy: 0.6390\n",
      "Epoch 227/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7802 - accuracy: 0.6380\n",
      "Epoch 228/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6383\n",
      "Epoch 229/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7792 - accuracy: 0.6389\n",
      "Epoch 230/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7793 - accuracy: 0.6377\n",
      "Epoch 231/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7790 - accuracy: 0.6392\n",
      "Epoch 232/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6382\n",
      "Epoch 233/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7786 - accuracy: 0.6388\n",
      "Epoch 234/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7803 - accuracy: 0.6387\n",
      "Epoch 235/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7797 - accuracy: 0.6374\n",
      "Epoch 236/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7794 - accuracy: 0.6399\n",
      "Epoch 237/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7786 - accuracy: 0.6397\n",
      "Epoch 238/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7785 - accuracy: 0.6400\n",
      "Epoch 239/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7806 - accuracy: 0.6384\n",
      "Epoch 240/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7797 - accuracy: 0.6381\n",
      "Epoch 241/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7803 - accuracy: 0.6387\n",
      "Epoch 242/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7812 - accuracy: 0.6377\n",
      "Epoch 243/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7807 - accuracy: 0.6381\n",
      "Epoch 244/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7793 - accuracy: 0.6387\n",
      "Epoch 245/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7790 - accuracy: 0.6391\n",
      "Epoch 246/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7798 - accuracy: 0.6405\n",
      "Epoch 247/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7784 - accuracy: 0.6390\n",
      "Epoch 248/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7783 - accuracy: 0.6396\n",
      "Epoch 249/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7776 - accuracy: 0.6390\n",
      "Epoch 250/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7779 - accuracy: 0.6403\n",
      "Epoch 251/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7782 - accuracy: 0.6396\n",
      "Epoch 252/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7792 - accuracy: 0.6389\n",
      "Epoch 253/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7782 - accuracy: 0.6392\n",
      "Epoch 254/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7779 - accuracy: 0.6397\n",
      "Epoch 255/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7786 - accuracy: 0.6392\n",
      "Epoch 256/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7783 - accuracy: 0.6387\n",
      "Epoch 257/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7784 - accuracy: 0.6394\n",
      "Epoch 258/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7782 - accuracy: 0.6396\n",
      "Epoch 259/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7775 - accuracy: 0.6397\n",
      "Epoch 260/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7773 - accuracy: 0.6397\n",
      "Epoch 261/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6403\n",
      "Epoch 262/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7773 - accuracy: 0.6403\n",
      "Epoch 263/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6395\n",
      "Epoch 264/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7792 - accuracy: 0.6394\n",
      "Epoch 265/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7784 - accuracy: 0.6392\n",
      "Epoch 266/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7777 - accuracy: 0.6398\n",
      "Epoch 267/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7775 - accuracy: 0.6404\n",
      "Epoch 268/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7774 - accuracy: 0.6400\n",
      "Epoch 269/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7813 - accuracy: 0.6383\n",
      "Epoch 270/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7789 - accuracy: 0.6387\n",
      "Epoch 271/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7779 - accuracy: 0.6397\n",
      "Epoch 272/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7780 - accuracy: 0.6392\n",
      "Epoch 273/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7795 - accuracy: 0.6390\n",
      "Epoch 274/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7773 - accuracy: 0.6403\n",
      "Epoch 275/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7768 - accuracy: 0.6409\n",
      "Epoch 276/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7769 - accuracy: 0.6415\n",
      "Epoch 277/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7777 - accuracy: 0.6405\n",
      "Epoch 278/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7773 - accuracy: 0.6410\n",
      "Epoch 279/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7766 - accuracy: 0.6404\n",
      "Epoch 280/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7767 - accuracy: 0.6397\n",
      "Epoch 281/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7764 - accuracy: 0.6399\n",
      "Epoch 282/300\n",
      "27247/27247 [==============================] - 1s 27us/step - loss: 0.7767 - accuracy: 0.6391\n",
      "Epoch 283/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7768 - accuracy: 0.6409\n",
      "Epoch 284/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7765 - accuracy: 0.6394\n",
      "Epoch 285/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7769 - accuracy: 0.6405\n",
      "Epoch 286/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7765 - accuracy: 0.6405\n",
      "Epoch 287/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7774 - accuracy: 0.6401\n",
      "Epoch 288/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7761 - accuracy: 0.6413\n",
      "Epoch 289/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7766 - accuracy: 0.6401\n",
      "Epoch 290/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7769 - accuracy: 0.6393\n",
      "Epoch 291/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7766 - accuracy: 0.6392\n",
      "Epoch 292/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7771 - accuracy: 0.6406\n",
      "Epoch 293/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7767 - accuracy: 0.6398\n",
      "Epoch 294/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7767 - accuracy: 0.6401\n",
      "Epoch 295/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7761 - accuracy: 0.6396\n",
      "Epoch 296/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7763 - accuracy: 0.6404\n",
      "Epoch 297/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7762 - accuracy: 0.6412\n",
      "Epoch 298/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7763 - accuracy: 0.6398\n",
      "Epoch 299/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7762 - accuracy: 0.6405\n",
      "Epoch 300/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7764 - accuracy: 0.6404\n",
      "6812/6812 [==============================] - 0s 39us/step\n",
      "Model evaluation  [0.7986055359165597, 0.6263945698738098]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=106, units=54, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=40, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=32, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "27247/27247 [==============================] - 1s 28us/step - loss: 1.3825 - accuracy: 0.5401\n",
      "Epoch 2/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 1.3718 - accuracy: 0.5493\n",
      "Epoch 3/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 1.3526 - accuracy: 0.5493\n",
      "Epoch 4/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 1.3042 - accuracy: 0.5493\n",
      "Epoch 5/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 1.1851 - accuracy: 0.5493\n",
      "Epoch 6/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 1.0391 - accuracy: 0.5493\n",
      "Epoch 7/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 1.0228 - accuracy: 0.5493\n",
      "Epoch 8/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9986 - accuracy: 0.5493\n",
      "Epoch 9/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9913 - accuracy: 0.5493\n",
      "Epoch 10/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9840 - accuracy: 0.5493\n",
      "Epoch 11/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9798 - accuracy: 0.5493\n",
      "Epoch 12/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9770 - accuracy: 0.5493\n",
      "Epoch 13/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9744 - accuracy: 0.5493\n",
      "Epoch 14/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9720 - accuracy: 0.5493\n",
      "Epoch 15/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9694 - accuracy: 0.5493\n",
      "Epoch 16/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9665 - accuracy: 0.5493\n",
      "Epoch 17/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9634 - accuracy: 0.5493\n",
      "Epoch 18/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9602 - accuracy: 0.5493\n",
      "Epoch 19/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9569 - accuracy: 0.5493\n",
      "Epoch 20/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9532 - accuracy: 0.5494\n",
      "Epoch 21/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9499 - accuracy: 0.5498\n",
      "Epoch 22/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9469 - accuracy: 0.5503\n",
      "Epoch 23/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9446 - accuracy: 0.5517\n",
      "Epoch 24/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9428 - accuracy: 0.5526\n",
      "Epoch 25/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9409 - accuracy: 0.5554\n",
      "Epoch 26/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9395 - accuracy: 0.5579\n",
      "Epoch 27/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9369 - accuracy: 0.5625\n",
      "Epoch 28/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9352 - accuracy: 0.5655\n",
      "Epoch 29/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9325 - accuracy: 0.5691\n",
      "Epoch 30/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9295 - accuracy: 0.5716\n",
      "Epoch 31/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9272 - accuracy: 0.5761\n",
      "Epoch 32/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9250 - accuracy: 0.5773\n",
      "Epoch 33/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9227 - accuracy: 0.5792\n",
      "Epoch 34/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9203 - accuracy: 0.5794\n",
      "Epoch 35/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9181 - accuracy: 0.5811\n",
      "Epoch 36/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9162 - accuracy: 0.5874\n",
      "Epoch 37/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9148 - accuracy: 0.5916\n",
      "Epoch 38/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9131 - accuracy: 0.5961\n",
      "Epoch 39/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9101 - accuracy: 0.5941\n",
      "Epoch 40/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9074 - accuracy: 0.5967\n",
      "Epoch 41/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9051 - accuracy: 0.5969\n",
      "Epoch 42/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9035 - accuracy: 0.5956\n",
      "Epoch 43/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9016 - accuracy: 0.5969\n",
      "Epoch 44/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9006 - accuracy: 0.5964\n",
      "Epoch 45/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8987 - accuracy: 0.5980\n",
      "Epoch 46/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8985 - accuracy: 0.5955\n",
      "Epoch 47/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8976 - accuracy: 0.5967\n",
      "Epoch 48/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8967 - accuracy: 0.5965\n",
      "Epoch 49/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8965 - accuracy: 0.5965\n",
      "Epoch 50/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8950 - accuracy: 0.5970\n",
      "Epoch 51/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8945 - accuracy: 0.5962\n",
      "Epoch 52/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8942 - accuracy: 0.5978\n",
      "Epoch 53/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8935 - accuracy: 0.5976\n",
      "Epoch 54/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8930 - accuracy: 0.5980\n",
      "Epoch 55/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8926 - accuracy: 0.5985\n",
      "Epoch 56/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8922 - accuracy: 0.5983\n",
      "Epoch 57/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8923 - accuracy: 0.5991\n",
      "Epoch 58/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8925 - accuracy: 0.5978\n",
      "Epoch 59/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8919 - accuracy: 0.5989\n",
      "Epoch 60/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8912 - accuracy: 0.5979\n",
      "Epoch 61/300\n",
      "27247/27247 [==============================] - 1s 26us/step - loss: 0.8909 - accuracy: 0.5989\n",
      "Epoch 62/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8903 - accuracy: 0.5992\n",
      "Epoch 63/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8900 - accuracy: 0.5996\n",
      "Epoch 64/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8896 - accuracy: 0.5992\n",
      "Epoch 65/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8895 - accuracy: 0.6002\n",
      "Epoch 66/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8895 - accuracy: 0.6002\n",
      "Epoch 67/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8895 - accuracy: 0.6000\n",
      "Epoch 68/300\n",
      "27247/27247 [==============================] - 1s 26us/step - loss: 0.8890 - accuracy: 0.5996\n",
      "Epoch 69/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8889 - accuracy: 0.6011\n",
      "Epoch 70/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8880 - accuracy: 0.6017\n",
      "Epoch 71/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8881 - accuracy: 0.6003\n",
      "Epoch 72/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8873 - accuracy: 0.6015\n",
      "Epoch 73/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8875 - accuracy: 0.6009\n",
      "Epoch 74/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8885 - accuracy: 0.6001\n",
      "Epoch 75/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8874 - accuracy: 0.6029\n",
      "Epoch 76/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8866 - accuracy: 0.6022\n",
      "Epoch 77/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8860 - accuracy: 0.6018\n",
      "Epoch 78/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8856 - accuracy: 0.6028\n",
      "Epoch 79/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8853 - accuracy: 0.6041\n",
      "Epoch 80/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8846 - accuracy: 0.6047\n",
      "Epoch 81/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8846 - accuracy: 0.6050\n",
      "Epoch 82/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8843 - accuracy: 0.6038\n",
      "Epoch 83/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8838 - accuracy: 0.6059\n",
      "Epoch 84/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8832 - accuracy: 0.6060\n",
      "Epoch 85/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8832 - accuracy: 0.6063\n",
      "Epoch 86/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8825 - accuracy: 0.6059\n",
      "Epoch 87/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8829 - accuracy: 0.6045\n",
      "Epoch 88/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8827 - accuracy: 0.6060\n",
      "Epoch 89/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8807 - accuracy: 0.6083\n",
      "Epoch 90/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8792 - accuracy: 0.6092\n",
      "Epoch 91/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8782 - accuracy: 0.6104\n",
      "Epoch 92/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8774 - accuracy: 0.6105\n",
      "Epoch 93/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8774 - accuracy: 0.6103\n",
      "Epoch 94/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8761 - accuracy: 0.6111\n",
      "Epoch 95/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8746 - accuracy: 0.6118\n",
      "Epoch 96/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8737 - accuracy: 0.6124\n",
      "Epoch 97/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8730 - accuracy: 0.6128\n",
      "Epoch 98/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8722 - accuracy: 0.6129\n",
      "Epoch 99/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8708 - accuracy: 0.6118\n",
      "Epoch 100/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8689 - accuracy: 0.6140\n",
      "Epoch 101/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8684 - accuracy: 0.6147\n",
      "Epoch 102/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8671 - accuracy: 0.6147\n",
      "Epoch 103/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8647 - accuracy: 0.6145\n",
      "Epoch 104/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8618 - accuracy: 0.6165\n",
      "Epoch 105/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8604 - accuracy: 0.6160\n",
      "Epoch 106/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8573 - accuracy: 0.6168\n",
      "Epoch 107/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8529 - accuracy: 0.6174\n",
      "Epoch 108/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8486 - accuracy: 0.6185\n",
      "Epoch 109/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8445 - accuracy: 0.6189\n",
      "Epoch 110/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8393 - accuracy: 0.6211\n",
      "Epoch 111/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8345 - accuracy: 0.6205\n",
      "Epoch 112/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8297 - accuracy: 0.6217\n",
      "Epoch 113/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8252 - accuracy: 0.6236\n",
      "Epoch 114/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8217 - accuracy: 0.6258\n",
      "Epoch 115/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8191 - accuracy: 0.6272\n",
      "Epoch 116/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8167 - accuracy: 0.6284\n",
      "Epoch 117/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8158 - accuracy: 0.6276\n",
      "Epoch 118/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8138 - accuracy: 0.6281\n",
      "Epoch 119/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8115 - accuracy: 0.6285\n",
      "Epoch 120/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8098 - accuracy: 0.6278\n",
      "Epoch 121/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8087 - accuracy: 0.6287\n",
      "Epoch 122/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8078 - accuracy: 0.6291\n",
      "Epoch 123/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8067 - accuracy: 0.6292\n",
      "Epoch 124/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8063 - accuracy: 0.6281\n",
      "Epoch 125/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8070 - accuracy: 0.6276\n",
      "Epoch 126/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8053 - accuracy: 0.6294\n",
      "Epoch 127/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8033 - accuracy: 0.6307\n",
      "Epoch 128/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8027 - accuracy: 0.6290\n",
      "Epoch 129/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8015 - accuracy: 0.6298\n",
      "Epoch 130/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8016 - accuracy: 0.6307\n",
      "Epoch 131/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8005 - accuracy: 0.6305\n",
      "Epoch 132/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8001 - accuracy: 0.6302\n",
      "Epoch 133/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8001 - accuracy: 0.6319\n",
      "Epoch 134/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7991 - accuracy: 0.6305\n",
      "Epoch 135/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7979 - accuracy: 0.6321\n",
      "Epoch 136/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7978 - accuracy: 0.6308\n",
      "Epoch 137/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7988 - accuracy: 0.6316\n",
      "Epoch 138/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7966 - accuracy: 0.6315\n",
      "Epoch 139/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7966 - accuracy: 0.6323\n",
      "Epoch 140/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7988 - accuracy: 0.6312\n",
      "Epoch 141/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7979 - accuracy: 0.6321\n",
      "Epoch 142/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7968 - accuracy: 0.6321\n",
      "Epoch 143/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7948 - accuracy: 0.6325\n",
      "Epoch 144/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7942 - accuracy: 0.6329\n",
      "Epoch 145/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7936 - accuracy: 0.6350\n",
      "Epoch 146/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7938 - accuracy: 0.6338\n",
      "Epoch 147/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7929 - accuracy: 0.6331\n",
      "Epoch 148/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7933 - accuracy: 0.6321\n",
      "Epoch 149/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7931 - accuracy: 0.6339\n",
      "Epoch 150/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7934 - accuracy: 0.6315\n",
      "Epoch 151/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7928 - accuracy: 0.6347\n",
      "Epoch 152/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7917 - accuracy: 0.6344\n",
      "Epoch 153/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7908 - accuracy: 0.6331\n",
      "Epoch 154/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7923 - accuracy: 0.6341\n",
      "Epoch 155/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7908 - accuracy: 0.6348\n",
      "Epoch 156/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7904 - accuracy: 0.6345\n",
      "Epoch 157/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7902 - accuracy: 0.6349\n",
      "Epoch 158/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7904 - accuracy: 0.6337\n",
      "Epoch 159/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7917 - accuracy: 0.6344\n",
      "Epoch 160/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7910 - accuracy: 0.6345\n",
      "Epoch 161/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7907 - accuracy: 0.6338\n",
      "Epoch 162/300\n",
      "27247/27247 [==============================] - 1s 28us/step - loss: 0.7890 - accuracy: 0.6352\n",
      "Epoch 163/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7885 - accuracy: 0.6358\n",
      "Epoch 164/300\n",
      "27247/27247 [==============================] - 1s 26us/step - loss: 0.7885 - accuracy: 0.6366\n",
      "Epoch 165/300\n",
      "27247/27247 [==============================] - 1s 26us/step - loss: 0.7876 - accuracy: 0.6361\n",
      "Epoch 166/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7880 - accuracy: 0.6358\n",
      "Epoch 167/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7888 - accuracy: 0.6357\n",
      "Epoch 168/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7881 - accuracy: 0.6362\n",
      "Epoch 169/300\n",
      "27247/27247 [==============================] - 1s 26us/step - loss: 0.7872 - accuracy: 0.6370\n",
      "Epoch 170/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7876 - accuracy: 0.6355\n",
      "Epoch 171/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7871 - accuracy: 0.6361\n",
      "Epoch 172/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7870 - accuracy: 0.6368\n",
      "Epoch 173/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7864 - accuracy: 0.6375\n",
      "Epoch 174/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7863 - accuracy: 0.6369\n",
      "Epoch 175/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7868 - accuracy: 0.6359\n",
      "Epoch 176/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7877 - accuracy: 0.6359\n",
      "Epoch 177/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7878 - accuracy: 0.6347\n",
      "Epoch 178/300\n",
      "27247/27247 [==============================] - 1s 26us/step - loss: 0.7858 - accuracy: 0.6373\n",
      "Epoch 179/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7859 - accuracy: 0.6366\n",
      "Epoch 180/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7857 - accuracy: 0.6368\n",
      "Epoch 181/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7861 - accuracy: 0.6374\n",
      "Epoch 182/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7846 - accuracy: 0.6381\n",
      "Epoch 183/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7843 - accuracy: 0.6377\n",
      "Epoch 184/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7843 - accuracy: 0.6373\n",
      "Epoch 185/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7847 - accuracy: 0.6372\n",
      "Epoch 186/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7854 - accuracy: 0.6384\n",
      "Epoch 187/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7850 - accuracy: 0.6374\n",
      "Epoch 188/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7842 - accuracy: 0.6379\n",
      "Epoch 189/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7836 - accuracy: 0.6386\n",
      "Epoch 190/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7840 - accuracy: 0.6382\n",
      "Epoch 191/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7846 - accuracy: 0.6371\n",
      "Epoch 192/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7844 - accuracy: 0.6382\n",
      "Epoch 193/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7841 - accuracy: 0.6381\n",
      "Epoch 194/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7845 - accuracy: 0.6370\n",
      "Epoch 195/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7832 - accuracy: 0.6378\n",
      "Epoch 196/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7831 - accuracy: 0.6392\n",
      "Epoch 197/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7836 - accuracy: 0.6371\n",
      "Epoch 198/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7835 - accuracy: 0.6371\n",
      "Epoch 199/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7830 - accuracy: 0.6386\n",
      "Epoch 200/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7846 - accuracy: 0.6367\n",
      "Epoch 201/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7845 - accuracy: 0.6372\n",
      "Epoch 202/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7838 - accuracy: 0.6377\n",
      "Epoch 203/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7829 - accuracy: 0.6385\n",
      "Epoch 204/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7826 - accuracy: 0.6400\n",
      "Epoch 205/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7825 - accuracy: 0.6381\n",
      "Epoch 206/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7832 - accuracy: 0.6382\n",
      "Epoch 207/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7840 - accuracy: 0.6368\n",
      "Epoch 208/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7820 - accuracy: 0.6386\n",
      "Epoch 209/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7821 - accuracy: 0.6384\n",
      "Epoch 210/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7816 - accuracy: 0.6393\n",
      "Epoch 211/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7823 - accuracy: 0.6372\n",
      "Epoch 212/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7817 - accuracy: 0.6392\n",
      "Epoch 213/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7831 - accuracy: 0.6381\n",
      "Epoch 214/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7822 - accuracy: 0.6384\n",
      "Epoch 215/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7833 - accuracy: 0.6376\n",
      "Epoch 216/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7836 - accuracy: 0.6372\n",
      "Epoch 217/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7813 - accuracy: 0.6394\n",
      "Epoch 218/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7812 - accuracy: 0.6395\n",
      "Epoch 219/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7807 - accuracy: 0.6386\n",
      "Epoch 220/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7808 - accuracy: 0.6377\n",
      "Epoch 221/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6403\n",
      "Epoch 222/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7798 - accuracy: 0.6398\n",
      "Epoch 223/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7807 - accuracy: 0.6393\n",
      "Epoch 224/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7800 - accuracy: 0.6390\n",
      "Epoch 225/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7802 - accuracy: 0.6401\n",
      "Epoch 226/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7804 - accuracy: 0.6397\n",
      "Epoch 227/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7815 - accuracy: 0.6392\n",
      "Epoch 228/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7814 - accuracy: 0.6399\n",
      "Epoch 229/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7795 - accuracy: 0.6398\n",
      "Epoch 230/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7792 - accuracy: 0.6414\n",
      "Epoch 231/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7791 - accuracy: 0.6401\n",
      "Epoch 232/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7790 - accuracy: 0.6403\n",
      "Epoch 233/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7789 - accuracy: 0.6399\n",
      "Epoch 234/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7789 - accuracy: 0.6410\n",
      "Epoch 235/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7786 - accuracy: 0.6392\n",
      "Epoch 236/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7794 - accuracy: 0.6407\n",
      "Epoch 237/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7802 - accuracy: 0.6392\n",
      "Epoch 238/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7807 - accuracy: 0.6401\n",
      "Epoch 239/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7805 - accuracy: 0.6391\n",
      "Epoch 240/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7799 - accuracy: 0.6400\n",
      "Epoch 241/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7789 - accuracy: 0.6403\n",
      "Epoch 242/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7791 - accuracy: 0.6397\n",
      "Epoch 243/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7806 - accuracy: 0.6401\n",
      "Epoch 244/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7809 - accuracy: 0.6397\n",
      "Epoch 245/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7794 - accuracy: 0.6401\n",
      "Epoch 246/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7814 - accuracy: 0.6397\n",
      "Epoch 247/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7803 - accuracy: 0.6398\n",
      "Epoch 248/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7798 - accuracy: 0.6408\n",
      "Epoch 249/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7794 - accuracy: 0.6406\n",
      "Epoch 250/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7791 - accuracy: 0.6417\n",
      "Epoch 251/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7794 - accuracy: 0.6408\n",
      "Epoch 252/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7796 - accuracy: 0.6406\n",
      "Epoch 253/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7796 - accuracy: 0.6395\n",
      "Epoch 254/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7796 - accuracy: 0.6407\n",
      "Epoch 255/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7783 - accuracy: 0.6407\n",
      "Epoch 256/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7795 - accuracy: 0.6403\n",
      "Epoch 257/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7787 - accuracy: 0.6402\n",
      "Epoch 258/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7779 - accuracy: 0.6411\n",
      "Epoch 259/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7788 - accuracy: 0.6407\n",
      "Epoch 260/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7778 - accuracy: 0.6414\n",
      "Epoch 261/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7782 - accuracy: 0.6415\n",
      "Epoch 262/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7768 - accuracy: 0.6424\n",
      "Epoch 263/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7782 - accuracy: 0.6405\n",
      "Epoch 264/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6428\n",
      "Epoch 265/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6423\n",
      "Epoch 266/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7778 - accuracy: 0.6411\n",
      "Epoch 267/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7785 - accuracy: 0.6409\n",
      "Epoch 268/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7777 - accuracy: 0.6416\n",
      "Epoch 269/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7776 - accuracy: 0.6422\n",
      "Epoch 270/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7772 - accuracy: 0.6404\n",
      "Epoch 271/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7764 - accuracy: 0.6427\n",
      "Epoch 272/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6413\n",
      "Epoch 273/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7763 - accuracy: 0.6425\n",
      "Epoch 274/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7767 - accuracy: 0.6430\n",
      "Epoch 275/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7768 - accuracy: 0.6422\n",
      "Epoch 276/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7769 - accuracy: 0.6428\n",
      "Epoch 277/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7765 - accuracy: 0.6427\n",
      "Epoch 278/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7765 - accuracy: 0.6424\n",
      "Epoch 279/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7763 - accuracy: 0.6422\n",
      "Epoch 280/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7758 - accuracy: 0.6435\n",
      "Epoch 281/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7777 - accuracy: 0.6421\n",
      "Epoch 282/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7765 - accuracy: 0.6418\n",
      "Epoch 283/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7755 - accuracy: 0.6438\n",
      "Epoch 284/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7760 - accuracy: 0.6429\n",
      "Epoch 285/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7758 - accuracy: 0.6418\n",
      "Epoch 286/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7752 - accuracy: 0.6439\n",
      "Epoch 287/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7759 - accuracy: 0.6432\n",
      "Epoch 288/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7760 - accuracy: 0.6419\n",
      "Epoch 289/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7752 - accuracy: 0.6433\n",
      "Epoch 290/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7750 - accuracy: 0.6439\n",
      "Epoch 291/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7763 - accuracy: 0.6426\n",
      "Epoch 292/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7759 - accuracy: 0.6436\n",
      "Epoch 293/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7754 - accuracy: 0.6429\n",
      "Epoch 294/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7742 - accuracy: 0.6441\n",
      "Epoch 295/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7750 - accuracy: 0.6432\n",
      "Epoch 296/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7745 - accuracy: 0.6441\n",
      "Epoch 297/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7743 - accuracy: 0.6435\n",
      "Epoch 298/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7740 - accuracy: 0.6437\n",
      "Epoch 299/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7746 - accuracy: 0.6432\n",
      "Epoch 300/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7759 - accuracy: 0.6423\n",
      "6812/6812 [==============================] - 0s 34us/step\n",
      "Model evaluation  [0.8047199603115469, 0.6327069997787476]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=106, units=54, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=40, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=32, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "27247/27247 [==============================] - 1s 27us/step - loss: 1.3828 - accuracy: 0.4959\n",
      "Epoch 2/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 1.3737 - accuracy: 0.5456\n",
      "Epoch 3/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 1.3593 - accuracy: 0.5456\n",
      "Epoch 4/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 1.3250 - accuracy: 0.5456\n",
      "Epoch 5/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 1.2326 - accuracy: 0.5456\n",
      "Epoch 6/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 1.0750 - accuracy: 0.5456\n",
      "Epoch 7/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 1.0251 - accuracy: 0.5456\n",
      "Epoch 8/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 1.0063 - accuracy: 0.5456\n",
      "Epoch 9/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9986 - accuracy: 0.5456\n",
      "Epoch 10/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9914 - accuracy: 0.5456\n",
      "Epoch 11/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9881 - accuracy: 0.5456\n",
      "Epoch 12/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9851 - accuracy: 0.5456\n",
      "Epoch 13/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9823 - accuracy: 0.5456\n",
      "Epoch 14/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9796 - accuracy: 0.5456\n",
      "Epoch 15/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.9767 - accuracy: 0.5456\n",
      "Epoch 16/300\n",
      "27247/27247 [==============================] - 1s 27us/step - loss: 0.9737 - accuracy: 0.5456\n",
      "Epoch 17/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9706 - accuracy: 0.5456\n",
      "Epoch 18/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9674 - accuracy: 0.5456\n",
      "Epoch 19/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9644 - accuracy: 0.5456\n",
      "Epoch 20/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9613 - accuracy: 0.5456\n",
      "Epoch 21/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9586 - accuracy: 0.5458\n",
      "Epoch 22/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9563 - accuracy: 0.5462\n",
      "Epoch 23/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9541 - accuracy: 0.5468\n",
      "Epoch 24/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9526 - accuracy: 0.5474\n",
      "Epoch 25/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9511 - accuracy: 0.5491\n",
      "Epoch 26/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9502 - accuracy: 0.5505\n",
      "Epoch 27/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9483 - accuracy: 0.5512\n",
      "Epoch 28/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9469 - accuracy: 0.5551\n",
      "Epoch 29/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9444 - accuracy: 0.5578\n",
      "Epoch 30/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9423 - accuracy: 0.5602\n",
      "Epoch 31/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9399 - accuracy: 0.5654\n",
      "Epoch 32/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9374 - accuracy: 0.5680\n",
      "Epoch 33/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9343 - accuracy: 0.5713\n",
      "Epoch 34/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9319 - accuracy: 0.5731\n",
      "Epoch 35/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9291 - accuracy: 0.5765\n",
      "Epoch 36/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9267 - accuracy: 0.5857\n",
      "Epoch 37/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9242 - accuracy: 0.5874\n",
      "Epoch 38/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9221 - accuracy: 0.5899\n",
      "Epoch 39/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9198 - accuracy: 0.5902\n",
      "Epoch 40/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9178 - accuracy: 0.5920\n",
      "Epoch 41/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9158 - accuracy: 0.5916\n",
      "Epoch 42/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9144 - accuracy: 0.5909\n",
      "Epoch 43/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9126 - accuracy: 0.5905\n",
      "Epoch 44/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9116 - accuracy: 0.5898\n",
      "Epoch 45/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9106 - accuracy: 0.5905\n",
      "Epoch 46/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9097 - accuracy: 0.5901\n",
      "Epoch 47/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9092 - accuracy: 0.5900\n",
      "Epoch 48/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9087 - accuracy: 0.5891\n",
      "Epoch 49/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9081 - accuracy: 0.5887\n",
      "Epoch 50/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9094 - accuracy: 0.5872\n",
      "Epoch 51/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9101 - accuracy: 0.5866\n",
      "Epoch 52/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9091 - accuracy: 0.5862\n",
      "Epoch 53/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9075 - accuracy: 0.5877\n",
      "Epoch 54/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9077 - accuracy: 0.5875\n",
      "Epoch 55/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9064 - accuracy: 0.5877\n",
      "Epoch 56/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9060 - accuracy: 0.5885\n",
      "Epoch 57/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9056 - accuracy: 0.5888\n",
      "Epoch 58/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9055 - accuracy: 0.5889\n",
      "Epoch 59/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9051 - accuracy: 0.5883\n",
      "Epoch 60/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9054 - accuracy: 0.5885\n",
      "Epoch 61/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9051 - accuracy: 0.5890\n",
      "Epoch 62/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9051 - accuracy: 0.5896\n",
      "Epoch 63/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9051 - accuracy: 0.5891\n",
      "Epoch 64/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9048 - accuracy: 0.5888\n",
      "Epoch 65/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9054 - accuracy: 0.5888\n",
      "Epoch 66/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9043 - accuracy: 0.5895\n",
      "Epoch 67/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9044 - accuracy: 0.5888\n",
      "Epoch 68/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9041 - accuracy: 0.5892\n",
      "Epoch 69/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9050 - accuracy: 0.5885\n",
      "Epoch 70/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9042 - accuracy: 0.5891\n",
      "Epoch 71/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9037 - accuracy: 0.5898\n",
      "Epoch 72/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9037 - accuracy: 0.5902\n",
      "Epoch 73/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9034 - accuracy: 0.5895\n",
      "Epoch 74/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9035 - accuracy: 0.5894\n",
      "Epoch 75/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9033 - accuracy: 0.5903\n",
      "Epoch 76/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9031 - accuracy: 0.5898\n",
      "Epoch 77/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9036 - accuracy: 0.5890\n",
      "Epoch 78/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9039 - accuracy: 0.5896\n",
      "Epoch 79/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9036 - accuracy: 0.5887\n",
      "Epoch 80/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9031 - accuracy: 0.5892\n",
      "Epoch 81/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9029 - accuracy: 0.5896\n",
      "Epoch 82/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9027 - accuracy: 0.5889\n",
      "Epoch 83/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9027 - accuracy: 0.5889\n",
      "Epoch 84/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9026 - accuracy: 0.5896\n",
      "Epoch 85/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9026 - accuracy: 0.5899\n",
      "Epoch 86/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9032 - accuracy: 0.5880\n",
      "Epoch 87/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9038 - accuracy: 0.5878\n",
      "Epoch 88/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9034 - accuracy: 0.5889\n",
      "Epoch 89/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9027 - accuracy: 0.5902\n",
      "Epoch 90/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9022 - accuracy: 0.5905\n",
      "Epoch 91/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9021 - accuracy: 0.5902\n",
      "Epoch 92/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9030 - accuracy: 0.5884\n",
      "Epoch 93/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9019 - accuracy: 0.5905\n",
      "Epoch 94/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9028 - accuracy: 0.5893\n",
      "Epoch 95/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9027 - accuracy: 0.5894\n",
      "Epoch 96/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9021 - accuracy: 0.5887\n",
      "Epoch 97/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9016 - accuracy: 0.5893\n",
      "Epoch 98/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9019 - accuracy: 0.5893\n",
      "Epoch 99/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9016 - accuracy: 0.5897\n",
      "Epoch 100/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9015 - accuracy: 0.5899\n",
      "Epoch 101/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9016 - accuracy: 0.5898\n",
      "Epoch 102/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9019 - accuracy: 0.5883\n",
      "Epoch 103/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9022 - accuracy: 0.5892\n",
      "Epoch 104/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9015 - accuracy: 0.5896\n",
      "Epoch 105/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9010 - accuracy: 0.5899\n",
      "Epoch 106/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9007 - accuracy: 0.5897\n",
      "Epoch 107/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9006 - accuracy: 0.5900\n",
      "Epoch 108/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9005 - accuracy: 0.5906\n",
      "Epoch 109/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.9011 - accuracy: 0.5895\n",
      "Epoch 110/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9005 - accuracy: 0.5896\n",
      "Epoch 111/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9004 - accuracy: 0.5893\n",
      "Epoch 112/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9003 - accuracy: 0.5894\n",
      "Epoch 113/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9003 - accuracy: 0.5895\n",
      "Epoch 114/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.9001 - accuracy: 0.5903\n",
      "Epoch 115/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9003 - accuracy: 0.5884\n",
      "Epoch 116/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9011 - accuracy: 0.5887\n",
      "Epoch 117/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.9000 - accuracy: 0.5896\n",
      "Epoch 118/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8997 - accuracy: 0.5892\n",
      "Epoch 119/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8997 - accuracy: 0.5895\n",
      "Epoch 120/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8998 - accuracy: 0.5883\n",
      "Epoch 121/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8986 - accuracy: 0.5898\n",
      "Epoch 122/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8988 - accuracy: 0.5895\n",
      "Epoch 123/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8985 - accuracy: 0.5893\n",
      "Epoch 124/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.8983 - accuracy: 0.5883\n",
      "Epoch 125/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8981 - accuracy: 0.5893\n",
      "Epoch 126/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8982 - accuracy: 0.5889\n",
      "Epoch 127/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8978 - accuracy: 0.5883\n",
      "Epoch 128/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8984 - accuracy: 0.5885\n",
      "Epoch 129/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8975 - accuracy: 0.5882\n",
      "Epoch 130/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8969 - accuracy: 0.5886\n",
      "Epoch 131/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8962 - accuracy: 0.5890\n",
      "Epoch 132/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8959 - accuracy: 0.5882\n",
      "Epoch 133/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8954 - accuracy: 0.5890\n",
      "Epoch 134/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8958 - accuracy: 0.5885\n",
      "Epoch 135/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8946 - accuracy: 0.5892\n",
      "Epoch 136/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8928 - accuracy: 0.5905\n",
      "Epoch 137/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8919 - accuracy: 0.5917\n",
      "Epoch 138/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8903 - accuracy: 0.5913\n",
      "Epoch 139/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8885 - accuracy: 0.5924\n",
      "Epoch 140/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8867 - accuracy: 0.5938\n",
      "Epoch 141/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8837 - accuracy: 0.5938\n",
      "Epoch 142/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8802 - accuracy: 0.5945\n",
      "Epoch 143/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8757 - accuracy: 0.5980\n",
      "Epoch 144/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8705 - accuracy: 0.5991\n",
      "Epoch 145/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8643 - accuracy: 0.6023\n",
      "Epoch 146/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8568 - accuracy: 0.6045\n",
      "Epoch 147/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8483 - accuracy: 0.6082\n",
      "Epoch 148/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8410 - accuracy: 0.6088\n",
      "Epoch 149/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8361 - accuracy: 0.6118\n",
      "Epoch 150/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8320 - accuracy: 0.6137\n",
      "Epoch 151/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8301 - accuracy: 0.6144\n",
      "Epoch 152/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8274 - accuracy: 0.6161\n",
      "Epoch 153/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8262 - accuracy: 0.6167\n",
      "Epoch 154/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.8238 - accuracy: 0.6164\n",
      "Epoch 155/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8225 - accuracy: 0.6178\n",
      "Epoch 156/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8221 - accuracy: 0.6181\n",
      "Epoch 157/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8212 - accuracy: 0.6192\n",
      "Epoch 158/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8168 - accuracy: 0.6195\n",
      "Epoch 159/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8145 - accuracy: 0.6214\n",
      "Epoch 160/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8134 - accuracy: 0.6209\n",
      "Epoch 161/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8130 - accuracy: 0.6234\n",
      "Epoch 162/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8123 - accuracy: 0.6214\n",
      "Epoch 163/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8118 - accuracy: 0.6231\n",
      "Epoch 164/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8101 - accuracy: 0.6232\n",
      "Epoch 165/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8083 - accuracy: 0.6235\n",
      "Epoch 166/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8077 - accuracy: 0.6245\n",
      "Epoch 167/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8099 - accuracy: 0.6234\n",
      "Epoch 168/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8089 - accuracy: 0.6243\n",
      "Epoch 169/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8084 - accuracy: 0.6244\n",
      "Epoch 170/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8067 - accuracy: 0.6246\n",
      "Epoch 171/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8072 - accuracy: 0.6266\n",
      "Epoch 172/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8053 - accuracy: 0.6260\n",
      "Epoch 173/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8033 - accuracy: 0.6265\n",
      "Epoch 174/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8039 - accuracy: 0.6258\n",
      "Epoch 175/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8044 - accuracy: 0.6273\n",
      "Epoch 176/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8023 - accuracy: 0.6269\n",
      "Epoch 177/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8021 - accuracy: 0.6277\n",
      "Epoch 178/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8026 - accuracy: 0.6262\n",
      "Epoch 179/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8025 - accuracy: 0.6279\n",
      "Epoch 180/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8013 - accuracy: 0.6276\n",
      "Epoch 181/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8008 - accuracy: 0.6277\n",
      "Epoch 182/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8012 - accuracy: 0.6280\n",
      "Epoch 183/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8012 - accuracy: 0.6274\n",
      "Epoch 184/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8006 - accuracy: 0.6287\n",
      "Epoch 185/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8002 - accuracy: 0.6293\n",
      "Epoch 186/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7997 - accuracy: 0.6285\n",
      "Epoch 187/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7992 - accuracy: 0.6303\n",
      "Epoch 188/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7988 - accuracy: 0.6295\n",
      "Epoch 189/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7989 - accuracy: 0.6281\n",
      "Epoch 190/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7983 - accuracy: 0.6296\n",
      "Epoch 191/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7991 - accuracy: 0.6301\n",
      "Epoch 192/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7995 - accuracy: 0.6286\n",
      "Epoch 193/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7991 - accuracy: 0.6298\n",
      "Epoch 194/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7989 - accuracy: 0.6297\n",
      "Epoch 195/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7985 - accuracy: 0.6310\n",
      "Epoch 196/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7985 - accuracy: 0.6296\n",
      "Epoch 197/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7977 - accuracy: 0.6309\n",
      "Epoch 198/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7968 - accuracy: 0.6314\n",
      "Epoch 199/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7981 - accuracy: 0.6314\n",
      "Epoch 200/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.8013 - accuracy: 0.6300\n",
      "Epoch 201/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7970 - accuracy: 0.6319\n",
      "Epoch 202/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7965 - accuracy: 0.6312\n",
      "Epoch 203/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7961 - accuracy: 0.6320\n",
      "Epoch 204/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7954 - accuracy: 0.6308\n",
      "Epoch 205/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7954 - accuracy: 0.6329\n",
      "Epoch 206/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7972 - accuracy: 0.6324\n",
      "Epoch 207/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7950 - accuracy: 0.6327\n",
      "Epoch 208/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7952 - accuracy: 0.6330\n",
      "Epoch 209/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7952 - accuracy: 0.6330\n",
      "Epoch 210/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7947 - accuracy: 0.6338\n",
      "Epoch 211/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7946 - accuracy: 0.6330\n",
      "Epoch 212/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7957 - accuracy: 0.6325\n",
      "Epoch 213/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7979 - accuracy: 0.6312\n",
      "Epoch 214/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7969 - accuracy: 0.6312\n",
      "Epoch 215/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7951 - accuracy: 0.6338\n",
      "Epoch 216/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7948 - accuracy: 0.6330\n",
      "Epoch 217/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7944 - accuracy: 0.6332\n",
      "Epoch 218/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7965 - accuracy: 0.6327\n",
      "Epoch 219/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7942 - accuracy: 0.6350\n",
      "Epoch 220/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7935 - accuracy: 0.6340\n",
      "Epoch 221/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7928 - accuracy: 0.6349\n",
      "Epoch 222/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7944 - accuracy: 0.6349\n",
      "Epoch 223/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7935 - accuracy: 0.6347\n",
      "Epoch 224/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7932 - accuracy: 0.6346\n",
      "Epoch 225/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7939 - accuracy: 0.6340\n",
      "Epoch 226/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7931 - accuracy: 0.6355\n",
      "Epoch 227/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7934 - accuracy: 0.6339\n",
      "Epoch 228/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7927 - accuracy: 0.6363\n",
      "Epoch 229/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7941 - accuracy: 0.6350\n",
      "Epoch 230/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7930 - accuracy: 0.6353\n",
      "Epoch 231/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7941 - accuracy: 0.6349\n",
      "Epoch 232/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7943 - accuracy: 0.6339\n",
      "Epoch 233/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7955 - accuracy: 0.6349\n",
      "Epoch 234/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7926 - accuracy: 0.6351\n",
      "Epoch 235/300\n",
      "27247/27247 [==============================] - 1s 25us/step - loss: 0.7915 - accuracy: 0.6363\n",
      "Epoch 236/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7918 - accuracy: 0.6356\n",
      "Epoch 237/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7919 - accuracy: 0.6356\n",
      "Epoch 238/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7939 - accuracy: 0.6352\n",
      "Epoch 239/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7937 - accuracy: 0.6343\n",
      "Epoch 240/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7934 - accuracy: 0.6364\n",
      "Epoch 241/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7942 - accuracy: 0.6364\n",
      "Epoch 242/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7935 - accuracy: 0.6359\n",
      "Epoch 243/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7927 - accuracy: 0.6354\n",
      "Epoch 244/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7915 - accuracy: 0.6365\n",
      "Epoch 245/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7918 - accuracy: 0.6369\n",
      "Epoch 246/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7932 - accuracy: 0.6360\n",
      "Epoch 247/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7921 - accuracy: 0.6360\n",
      "Epoch 248/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7908 - accuracy: 0.6372\n",
      "Epoch 249/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7911 - accuracy: 0.6369\n",
      "Epoch 250/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7908 - accuracy: 0.6369\n",
      "Epoch 251/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7909 - accuracy: 0.6376\n",
      "Epoch 252/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7901 - accuracy: 0.6371\n",
      "Epoch 253/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7909 - accuracy: 0.6364\n",
      "Epoch 254/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7912 - accuracy: 0.6365\n",
      "Epoch 255/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7916 - accuracy: 0.6357\n",
      "Epoch 256/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7957 - accuracy: 0.6348\n",
      "Epoch 257/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7910 - accuracy: 0.6360\n",
      "Epoch 258/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7908 - accuracy: 0.6363\n",
      "Epoch 259/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7915 - accuracy: 0.6365\n",
      "Epoch 260/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7910 - accuracy: 0.6373\n",
      "Epoch 261/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7902 - accuracy: 0.6361\n",
      "Epoch 262/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7896 - accuracy: 0.6367\n",
      "Epoch 263/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7908 - accuracy: 0.6375\n",
      "Epoch 264/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7902 - accuracy: 0.6372\n",
      "Epoch 265/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7901 - accuracy: 0.6366\n",
      "Epoch 266/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7890 - accuracy: 0.6371\n",
      "Epoch 267/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7893 - accuracy: 0.6372\n",
      "Epoch 268/300\n",
      "27247/27247 [==============================] - 1s 24us/step - loss: 0.7899 - accuracy: 0.6365\n",
      "Epoch 269/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7902 - accuracy: 0.6371\n",
      "Epoch 270/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7894 - accuracy: 0.6374\n",
      "Epoch 271/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7891 - accuracy: 0.6383\n",
      "Epoch 272/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7898 - accuracy: 0.6364\n",
      "Epoch 273/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7909 - accuracy: 0.6372\n",
      "Epoch 274/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7895 - accuracy: 0.6374\n",
      "Epoch 275/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7890 - accuracy: 0.6383\n",
      "Epoch 276/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7909 - accuracy: 0.6366\n",
      "Epoch 277/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7900 - accuracy: 0.6376\n",
      "Epoch 278/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7889 - accuracy: 0.6382\n",
      "Epoch 279/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7889 - accuracy: 0.6382\n",
      "Epoch 280/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7888 - accuracy: 0.6374\n",
      "Epoch 281/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7887 - accuracy: 0.6379\n",
      "Epoch 282/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7885 - accuracy: 0.6375\n",
      "Epoch 283/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7892 - accuracy: 0.6377\n",
      "Epoch 284/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7886 - accuracy: 0.6384\n",
      "Epoch 285/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7882 - accuracy: 0.6382\n",
      "Epoch 286/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7894 - accuracy: 0.6372\n",
      "Epoch 287/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7886 - accuracy: 0.6386\n",
      "Epoch 288/300\n",
      "27247/27247 [==============================] - 1s 22us/step - loss: 0.7883 - accuracy: 0.6388\n",
      "Epoch 289/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7893 - accuracy: 0.6380\n",
      "Epoch 290/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7892 - accuracy: 0.6380\n",
      "Epoch 291/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7884 - accuracy: 0.6380\n",
      "Epoch 292/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7881 - accuracy: 0.6383\n",
      "Epoch 293/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7895 - accuracy: 0.6385\n",
      "Epoch 294/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7912 - accuracy: 0.6371\n",
      "Epoch 295/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7883 - accuracy: 0.6379\n",
      "Epoch 296/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7886 - accuracy: 0.6380\n",
      "Epoch 297/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7884 - accuracy: 0.6378\n",
      "Epoch 298/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7897 - accuracy: 0.6390\n",
      "Epoch 299/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7876 - accuracy: 0.6393\n",
      "Epoch 300/300\n",
      "27247/27247 [==============================] - 1s 23us/step - loss: 0.7874 - accuracy: 0.6382\n",
      "6812/6812 [==============================] - 0s 46us/step\n",
      "Model evaluation  [0.7821379680529945, 0.6425426006317139]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=106, units=54, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=40, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=32, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/home/jaeheuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "27248/27248 [==============================] - 1s 27us/step - loss: 1.3830 - accuracy: 0.3158\n",
      "Epoch 2/300\n",
      "27248/27248 [==============================] - 1s 22us/step - loss: 1.3750 - accuracy: 0.3365\n",
      "Epoch 3/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 1.3635 - accuracy: 0.3365\n",
      "Epoch 4/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 1.3380 - accuracy: 0.3365\n",
      "Epoch 5/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 1.2656 - accuracy: 0.3365\n",
      "Epoch 6/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 1.1167 - accuracy: 0.4103\n",
      "Epoch 7/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 1.0155 - accuracy: 0.5497\n",
      "Epoch 8/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 1.0070 - accuracy: 0.5497\n",
      "Epoch 9/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9894 - accuracy: 0.5497\n",
      "Epoch 10/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9848 - accuracy: 0.5497\n",
      "Epoch 11/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9809 - accuracy: 0.5497\n",
      "Epoch 12/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9788 - accuracy: 0.5497\n",
      "Epoch 13/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.9771 - accuracy: 0.5497\n",
      "Epoch 14/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9758 - accuracy: 0.5497\n",
      "Epoch 15/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9745 - accuracy: 0.5497\n",
      "Epoch 16/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.9731 - accuracy: 0.5497\n",
      "Epoch 17/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.9718 - accuracy: 0.5497\n",
      "Epoch 18/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9706 - accuracy: 0.5497\n",
      "Epoch 19/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9693 - accuracy: 0.5497\n",
      "Epoch 20/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9680 - accuracy: 0.5497\n",
      "Epoch 21/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9665 - accuracy: 0.5497\n",
      "Epoch 22/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9650 - accuracy: 0.5497\n",
      "Epoch 23/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9636 - accuracy: 0.5497\n",
      "Epoch 24/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9618 - accuracy: 0.5497\n",
      "Epoch 25/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.9601 - accuracy: 0.5497\n",
      "Epoch 26/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.9580 - accuracy: 0.5497\n",
      "Epoch 27/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9560 - accuracy: 0.5497\n",
      "Epoch 28/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9538 - accuracy: 0.5498\n",
      "Epoch 29/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9514 - accuracy: 0.5502\n",
      "Epoch 30/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9489 - accuracy: 0.5509\n",
      "Epoch 31/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9466 - accuracy: 0.5526\n",
      "Epoch 32/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9442 - accuracy: 0.5566\n",
      "Epoch 33/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9409 - accuracy: 0.5616\n",
      "Epoch 34/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9388 - accuracy: 0.5673\n",
      "Epoch 35/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.9357 - accuracy: 0.5729\n",
      "Epoch 36/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.9331 - accuracy: 0.5755\n",
      "Epoch 37/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.9308 - accuracy: 0.5777\n",
      "Epoch 38/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.9296 - accuracy: 0.5787\n",
      "Epoch 39/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9281 - accuracy: 0.5807\n",
      "Epoch 40/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.9260 - accuracy: 0.5806\n",
      "Epoch 41/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9246 - accuracy: 0.5822\n",
      "Epoch 42/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9222 - accuracy: 0.5838\n",
      "Epoch 43/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9198 - accuracy: 0.5875\n",
      "Epoch 44/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9182 - accuracy: 0.5928\n",
      "Epoch 45/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9158 - accuracy: 0.5934\n",
      "Epoch 46/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.9139 - accuracy: 0.5945\n",
      "Epoch 47/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.9121 - accuracy: 0.5970\n",
      "Epoch 48/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9101 - accuracy: 0.5981\n",
      "Epoch 49/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9098 - accuracy: 0.5977\n",
      "Epoch 50/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9084 - accuracy: 0.5987\n",
      "Epoch 51/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9080 - accuracy: 0.5961\n",
      "Epoch 52/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9059 - accuracy: 0.5964\n",
      "Epoch 53/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9039 - accuracy: 0.5986\n",
      "Epoch 54/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9028 - accuracy: 0.5982\n",
      "Epoch 55/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9021 - accuracy: 0.5968\n",
      "Epoch 56/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9013 - accuracy: 0.5971\n",
      "Epoch 57/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.9011 - accuracy: 0.5963\n",
      "Epoch 58/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8997 - accuracy: 0.5961\n",
      "Epoch 59/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8989 - accuracy: 0.5959\n",
      "Epoch 60/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8986 - accuracy: 0.5955\n",
      "Epoch 61/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8979 - accuracy: 0.5943\n",
      "Epoch 62/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8981 - accuracy: 0.5945\n",
      "Epoch 63/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8971 - accuracy: 0.5946\n",
      "Epoch 64/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8960 - accuracy: 0.5949\n",
      "Epoch 65/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8961 - accuracy: 0.5948\n",
      "Epoch 66/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8953 - accuracy: 0.5947\n",
      "Epoch 67/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.8950 - accuracy: 0.5942\n",
      "Epoch 68/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8950 - accuracy: 0.5952\n",
      "Epoch 69/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8948 - accuracy: 0.5944\n",
      "Epoch 70/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8936 - accuracy: 0.5955\n",
      "Epoch 71/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8927 - accuracy: 0.5961\n",
      "Epoch 72/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8925 - accuracy: 0.5964\n",
      "Epoch 73/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8919 - accuracy: 0.5959\n",
      "Epoch 74/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8914 - accuracy: 0.5962\n",
      "Epoch 75/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8910 - accuracy: 0.5980\n",
      "Epoch 76/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8907 - accuracy: 0.5967\n",
      "Epoch 77/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8904 - accuracy: 0.5984\n",
      "Epoch 78/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.8911 - accuracy: 0.5963\n",
      "Epoch 79/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8906 - accuracy: 0.5995\n",
      "Epoch 80/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8894 - accuracy: 0.5986\n",
      "Epoch 81/300\n",
      "27248/27248 [==============================] - 1s 26us/step - loss: 0.8894 - accuracy: 0.6005\n",
      "Epoch 82/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.8888 - accuracy: 0.5997\n",
      "Epoch 83/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8875 - accuracy: 0.6011\n",
      "Epoch 84/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8862 - accuracy: 0.6021\n",
      "Epoch 85/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8855 - accuracy: 0.6033\n",
      "Epoch 86/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8846 - accuracy: 0.6040\n",
      "Epoch 87/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8836 - accuracy: 0.6045\n",
      "Epoch 88/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8834 - accuracy: 0.6049\n",
      "Epoch 89/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8815 - accuracy: 0.6072\n",
      "Epoch 90/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8787 - accuracy: 0.6088\n",
      "Epoch 91/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8766 - accuracy: 0.6091\n",
      "Epoch 92/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8726 - accuracy: 0.6122\n",
      "Epoch 93/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8685 - accuracy: 0.6153\n",
      "Epoch 94/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8637 - accuracy: 0.6151\n",
      "Epoch 95/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8578 - accuracy: 0.6161\n",
      "Epoch 96/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8519 - accuracy: 0.6173\n",
      "Epoch 97/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8460 - accuracy: 0.6174\n",
      "Epoch 98/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8403 - accuracy: 0.6193\n",
      "Epoch 99/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.8357 - accuracy: 0.6207\n",
      "Epoch 100/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8311 - accuracy: 0.6208\n",
      "Epoch 101/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8266 - accuracy: 0.6231\n",
      "Epoch 102/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8220 - accuracy: 0.6254\n",
      "Epoch 103/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8176 - accuracy: 0.6283\n",
      "Epoch 104/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.8165 - accuracy: 0.6258\n",
      "Epoch 105/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8132 - accuracy: 0.6290\n",
      "Epoch 106/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8105 - accuracy: 0.6291\n",
      "Epoch 107/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8090 - accuracy: 0.6295\n",
      "Epoch 108/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8072 - accuracy: 0.6301\n",
      "Epoch 109/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8058 - accuracy: 0.6296\n",
      "Epoch 110/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8050 - accuracy: 0.6306\n",
      "Epoch 111/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8039 - accuracy: 0.6296\n",
      "Epoch 112/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8032 - accuracy: 0.6292\n",
      "Epoch 113/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8036 - accuracy: 0.6299\n",
      "Epoch 114/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.8040 - accuracy: 0.6296\n",
      "Epoch 115/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.8026 - accuracy: 0.6304\n",
      "Epoch 116/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.8010 - accuracy: 0.6298\n",
      "Epoch 117/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7998 - accuracy: 0.6314\n",
      "Epoch 118/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.8005 - accuracy: 0.6297\n",
      "Epoch 119/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.7996 - accuracy: 0.6319\n",
      "Epoch 120/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.7997 - accuracy: 0.6308\n",
      "Epoch 121/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7990 - accuracy: 0.6309\n",
      "Epoch 122/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7970 - accuracy: 0.6304\n",
      "Epoch 123/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7965 - accuracy: 0.6312\n",
      "Epoch 124/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7959 - accuracy: 0.6316\n",
      "Epoch 125/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7955 - accuracy: 0.6305\n",
      "Epoch 126/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7946 - accuracy: 0.6325\n",
      "Epoch 127/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7945 - accuracy: 0.6318\n",
      "Epoch 128/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7940 - accuracy: 0.6323\n",
      "Epoch 129/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7945 - accuracy: 0.6320\n",
      "Epoch 130/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7935 - accuracy: 0.6327\n",
      "Epoch 131/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7935 - accuracy: 0.6315\n",
      "Epoch 132/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7932 - accuracy: 0.6322\n",
      "Epoch 133/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7931 - accuracy: 0.6336\n",
      "Epoch 134/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7951 - accuracy: 0.6318\n",
      "Epoch 135/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7937 - accuracy: 0.6327\n",
      "Epoch 136/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7925 - accuracy: 0.6324\n",
      "Epoch 137/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7915 - accuracy: 0.6330\n",
      "Epoch 138/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7920 - accuracy: 0.6333\n",
      "Epoch 139/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7913 - accuracy: 0.6336\n",
      "Epoch 140/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7906 - accuracy: 0.6326\n",
      "Epoch 141/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7902 - accuracy: 0.6326\n",
      "Epoch 142/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7908 - accuracy: 0.6324\n",
      "Epoch 143/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7913 - accuracy: 0.6331\n",
      "Epoch 144/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7897 - accuracy: 0.6334\n",
      "Epoch 145/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7904 - accuracy: 0.6338\n",
      "Epoch 146/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7907 - accuracy: 0.6346\n",
      "Epoch 147/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7903 - accuracy: 0.6338\n",
      "Epoch 148/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7891 - accuracy: 0.6337\n",
      "Epoch 149/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7888 - accuracy: 0.6344\n",
      "Epoch 150/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7884 - accuracy: 0.6343\n",
      "Epoch 151/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7881 - accuracy: 0.6347\n",
      "Epoch 152/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7881 - accuracy: 0.6336\n",
      "Epoch 153/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7875 - accuracy: 0.6341\n",
      "Epoch 154/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7884 - accuracy: 0.6340\n",
      "Epoch 155/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7883 - accuracy: 0.6348\n",
      "Epoch 156/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7878 - accuracy: 0.6345\n",
      "Epoch 157/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7878 - accuracy: 0.6342\n",
      "Epoch 158/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7870 - accuracy: 0.6352\n",
      "Epoch 159/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7869 - accuracy: 0.6361\n",
      "Epoch 160/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7877 - accuracy: 0.6355\n",
      "Epoch 161/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7865 - accuracy: 0.6339\n",
      "Epoch 162/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7870 - accuracy: 0.6353\n",
      "Epoch 163/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7883 - accuracy: 0.6349\n",
      "Epoch 164/300\n",
      "27248/27248 [==============================] - 1s 22us/step - loss: 0.7864 - accuracy: 0.6349\n",
      "Epoch 165/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7863 - accuracy: 0.6360\n",
      "Epoch 166/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7862 - accuracy: 0.6358\n",
      "Epoch 167/300\n",
      "27248/27248 [==============================] - 1s 22us/step - loss: 0.7864 - accuracy: 0.6367\n",
      "Epoch 168/300\n",
      "27248/27248 [==============================] - 1s 22us/step - loss: 0.7852 - accuracy: 0.6367\n",
      "Epoch 169/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7850 - accuracy: 0.6363\n",
      "Epoch 170/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7849 - accuracy: 0.6352\n",
      "Epoch 171/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7844 - accuracy: 0.6360\n",
      "Epoch 172/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7854 - accuracy: 0.6356\n",
      "Epoch 173/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7849 - accuracy: 0.6361\n",
      "Epoch 174/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.7838 - accuracy: 0.6365\n",
      "Epoch 175/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.7843 - accuracy: 0.6363\n",
      "Epoch 176/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7837 - accuracy: 0.6367\n",
      "Epoch 177/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7836 - accuracy: 0.6365\n",
      "Epoch 178/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7856 - accuracy: 0.6357\n",
      "Epoch 179/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7844 - accuracy: 0.6362\n",
      "Epoch 180/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7829 - accuracy: 0.6365\n",
      "Epoch 181/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7840 - accuracy: 0.6362\n",
      "Epoch 182/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7853 - accuracy: 0.6365\n",
      "Epoch 183/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7848 - accuracy: 0.6379\n",
      "Epoch 184/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7863 - accuracy: 0.6348\n",
      "Epoch 185/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.7847 - accuracy: 0.6367\n",
      "Epoch 186/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7853 - accuracy: 0.6364\n",
      "Epoch 187/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7844 - accuracy: 0.6371\n",
      "Epoch 188/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7823 - accuracy: 0.6368\n",
      "Epoch 189/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7820 - accuracy: 0.6383\n",
      "Epoch 190/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7818 - accuracy: 0.6376\n",
      "Epoch 191/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.7822 - accuracy: 0.6380\n",
      "Epoch 192/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7822 - accuracy: 0.6378\n",
      "Epoch 193/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7822 - accuracy: 0.6371\n",
      "Epoch 194/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7815 - accuracy: 0.6386\n",
      "Epoch 195/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7818 - accuracy: 0.6384\n",
      "Epoch 196/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7817 - accuracy: 0.6373\n",
      "Epoch 197/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7816 - accuracy: 0.6371\n",
      "Epoch 198/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7808 - accuracy: 0.6381\n",
      "Epoch 199/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7808 - accuracy: 0.6384\n",
      "Epoch 200/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7811 - accuracy: 0.6387\n",
      "Epoch 201/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7833 - accuracy: 0.6366\n",
      "Epoch 202/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7817 - accuracy: 0.6382\n",
      "Epoch 203/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7816 - accuracy: 0.6380\n",
      "Epoch 204/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7808 - accuracy: 0.6378\n",
      "Epoch 205/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7803 - accuracy: 0.6392\n",
      "Epoch 206/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7802 - accuracy: 0.6384\n",
      "Epoch 207/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7806 - accuracy: 0.6394\n",
      "Epoch 208/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7805 - accuracy: 0.6395\n",
      "Epoch 209/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6382\n",
      "Epoch 210/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7799 - accuracy: 0.6400\n",
      "Epoch 211/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7805 - accuracy: 0.6389\n",
      "Epoch 212/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7807 - accuracy: 0.6398\n",
      "Epoch 213/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7805 - accuracy: 0.6382\n",
      "Epoch 214/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7811 - accuracy: 0.6373\n",
      "Epoch 215/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7817 - accuracy: 0.6370\n",
      "Epoch 216/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7795 - accuracy: 0.6394\n",
      "Epoch 217/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7788 - accuracy: 0.6396\n",
      "Epoch 218/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7796 - accuracy: 0.6386\n",
      "Epoch 219/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7816 - accuracy: 0.6382\n",
      "Epoch 220/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7805 - accuracy: 0.6382\n",
      "Epoch 221/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7818 - accuracy: 0.6374\n",
      "Epoch 222/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7798 - accuracy: 0.6381\n",
      "Epoch 223/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7821 - accuracy: 0.6392\n",
      "Epoch 224/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7829 - accuracy: 0.6382\n",
      "Epoch 225/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7812 - accuracy: 0.6386\n",
      "Epoch 226/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7783 - accuracy: 0.6404\n",
      "Epoch 227/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7782 - accuracy: 0.6393\n",
      "Epoch 228/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7783 - accuracy: 0.6395\n",
      "Epoch 229/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7780 - accuracy: 0.6408\n",
      "Epoch 230/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7780 - accuracy: 0.6399\n",
      "Epoch 231/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7778 - accuracy: 0.6403\n",
      "Epoch 232/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7790 - accuracy: 0.6404\n",
      "Epoch 233/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7784 - accuracy: 0.6393\n",
      "Epoch 234/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7779 - accuracy: 0.6400\n",
      "Epoch 235/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7776 - accuracy: 0.6404\n",
      "Epoch 236/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7783 - accuracy: 0.6403\n",
      "Epoch 237/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7781 - accuracy: 0.6396\n",
      "Epoch 238/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7789 - accuracy: 0.6387\n",
      "Epoch 239/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7780 - accuracy: 0.6407\n",
      "Epoch 240/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7785 - accuracy: 0.6403\n",
      "Epoch 241/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7778 - accuracy: 0.6392\n",
      "Epoch 242/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7769 - accuracy: 0.6407\n",
      "Epoch 243/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7767 - accuracy: 0.6414\n",
      "Epoch 244/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7773 - accuracy: 0.6389\n",
      "Epoch 245/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6407\n",
      "Epoch 246/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7776 - accuracy: 0.6412\n",
      "Epoch 247/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7768 - accuracy: 0.6413\n",
      "Epoch 248/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7766 - accuracy: 0.6406\n",
      "Epoch 249/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7773 - accuracy: 0.6421\n",
      "Epoch 250/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7775 - accuracy: 0.6399\n",
      "Epoch 251/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6412\n",
      "Epoch 252/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6417\n",
      "Epoch 253/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7769 - accuracy: 0.6410\n",
      "Epoch 254/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7772 - accuracy: 0.6408\n",
      "Epoch 255/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7773 - accuracy: 0.6411\n",
      "Epoch 256/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7773 - accuracy: 0.6406\n",
      "Epoch 257/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7767 - accuracy: 0.6410\n",
      "Epoch 258/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7768 - accuracy: 0.6413\n",
      "Epoch 259/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7768 - accuracy: 0.6419\n",
      "Epoch 260/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7769 - accuracy: 0.6416\n",
      "Epoch 261/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7771 - accuracy: 0.6413\n",
      "Epoch 262/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7759 - accuracy: 0.6406\n",
      "Epoch 263/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7757 - accuracy: 0.6411\n",
      "Epoch 264/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7758 - accuracy: 0.6409\n",
      "Epoch 265/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7756 - accuracy: 0.6427\n",
      "Epoch 266/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7754 - accuracy: 0.6414\n",
      "Epoch 267/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7770 - accuracy: 0.6406\n",
      "Epoch 268/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7767 - accuracy: 0.6408\n",
      "Epoch 269/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7760 - accuracy: 0.6411\n",
      "Epoch 270/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7761 - accuracy: 0.6417\n",
      "Epoch 271/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7753 - accuracy: 0.6420\n",
      "Epoch 272/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7760 - accuracy: 0.6417\n",
      "Epoch 273/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7757 - accuracy: 0.6415\n",
      "Epoch 274/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7757 - accuracy: 0.6423\n",
      "Epoch 275/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7761 - accuracy: 0.6420\n",
      "Epoch 276/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7752 - accuracy: 0.6434\n",
      "Epoch 277/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7749 - accuracy: 0.6422\n",
      "Epoch 278/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7752 - accuracy: 0.6424\n",
      "Epoch 279/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7760 - accuracy: 0.6413\n",
      "Epoch 280/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7756 - accuracy: 0.6415\n",
      "Epoch 281/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7754 - accuracy: 0.6420\n",
      "Epoch 282/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7745 - accuracy: 0.6413\n",
      "Epoch 283/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7750 - accuracy: 0.6421\n",
      "Epoch 284/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7744 - accuracy: 0.6429\n",
      "Epoch 285/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7746 - accuracy: 0.6421\n",
      "Epoch 286/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7747 - accuracy: 0.6425\n",
      "Epoch 287/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7747 - accuracy: 0.6423\n",
      "Epoch 288/300\n",
      "27248/27248 [==============================] - 1s 26us/step - loss: 0.7741 - accuracy: 0.6433\n",
      "Epoch 289/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7743 - accuracy: 0.6421\n",
      "Epoch 290/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.7756 - accuracy: 0.6416\n",
      "Epoch 291/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.7748 - accuracy: 0.6432\n",
      "Epoch 292/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7752 - accuracy: 0.6427\n",
      "Epoch 293/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7744 - accuracy: 0.6422\n",
      "Epoch 294/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7741 - accuracy: 0.6427\n",
      "Epoch 295/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.7754 - accuracy: 0.6420\n",
      "Epoch 296/300\n",
      "27248/27248 [==============================] - 1s 25us/step - loss: 0.7755 - accuracy: 0.6412\n",
      "Epoch 297/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7760 - accuracy: 0.6423\n",
      "Epoch 298/300\n",
      "27248/27248 [==============================] - 1s 24us/step - loss: 0.7743 - accuracy: 0.6438\n",
      "Epoch 299/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7752 - accuracy: 0.6418\n",
      "Epoch 300/300\n",
      "27248/27248 [==============================] - 1s 23us/step - loss: 0.7757 - accuracy: 0.6418\n",
      "6811/6811 [==============================] - 0s 49us/step\n",
      "Model evaluation  [0.8499737959866516, 0.6134194731712341]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_split =5\n",
    "\n",
    "for train_index,test_index in KFold(n_split).split(X_one):\n",
    "    x_train,x_test=X_one.iloc[train_index],X_one.iloc[test_index]\n",
    "    y_train,y_test=y_one.iloc[train_index],y_one.iloc[test_index]\n",
    "    split_model=model_fit()\n",
    "    split_model.fit(x_train, y_train,epochs=300,batch_size = 3036)\n",
    "    print('Model evaluation ',split_model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jaeheuk/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/300\n",
      "30653/30653 [==============================] - 1s 36us/step - loss: 1.3793 - accuracy: 0.5222\n",
      "Epoch 2/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 1.3487 - accuracy: 0.5519\n",
      "Epoch 3/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 1.1809 - accuracy: 0.5519\n",
      "Epoch 4/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 1.0134 - accuracy: 0.5519\n",
      "Epoch 5/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9902 - accuracy: 0.5519\n",
      "Epoch 6/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9799 - accuracy: 0.5519\n",
      "Epoch 7/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9739 - accuracy: 0.5519\n",
      "Epoch 8/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.9695 - accuracy: 0.5519\n",
      "Epoch 9/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.9655 - accuracy: 0.5519\n",
      "Epoch 10/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9618 - accuracy: 0.5519\n",
      "Epoch 11/300\n",
      "30653/30653 [==============================] - 1s 25us/step - loss: 0.9572 - accuracy: 0.5519\n",
      "Epoch 12/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.9531 - accuracy: 0.5520\n",
      "Epoch 13/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9490 - accuracy: 0.5524\n",
      "Epoch 14/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9458 - accuracy: 0.5539\n",
      "Epoch 15/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.9425 - accuracy: 0.5579\n",
      "Epoch 16/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9395 - accuracy: 0.5651\n",
      "Epoch 17/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.9341 - accuracy: 0.5750\n",
      "Epoch 18/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9298 - accuracy: 0.5779\n",
      "Epoch 19/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9267 - accuracy: 0.5808\n",
      "Epoch 20/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9227 - accuracy: 0.5824\n",
      "Epoch 21/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.9188 - accuracy: 0.5878\n",
      "Epoch 22/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.9153 - accuracy: 0.5945 0s - loss: 0.9137 - accuracy: \n",
      "Epoch 23/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9121 - accuracy: 0.5966\n",
      "Epoch 24/300\n",
      "30653/30653 [==============================] - 1s 25us/step - loss: 0.9090 - accuracy: 0.5962\n",
      "Epoch 25/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9064 - accuracy: 0.5963\n",
      "Epoch 26/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.9046 - accuracy: 0.5954\n",
      "Epoch 27/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.9035 - accuracy: 0.5945\n",
      "Epoch 28/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9021 - accuracy: 0.5927\n",
      "Epoch 29/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9004 - accuracy: 0.5938\n",
      "Epoch 30/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.9001 - accuracy: 0.5936\n",
      "Epoch 31/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8979 - accuracy: 0.5946\n",
      "Epoch 32/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8970 - accuracy: 0.5920\n",
      "Epoch 33/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8962 - accuracy: 0.5935\n",
      "Epoch 34/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8953 - accuracy: 0.5935\n",
      "Epoch 35/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8945 - accuracy: 0.5929\n",
      "Epoch 36/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8931 - accuracy: 0.5941\n",
      "Epoch 37/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8925 - accuracy: 0.5929\n",
      "Epoch 38/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8923 - accuracy: 0.5919\n",
      "Epoch 39/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8906 - accuracy: 0.5929\n",
      "Epoch 40/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8897 - accuracy: 0.5926\n",
      "Epoch 41/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8887 - accuracy: 0.5927\n",
      "Epoch 42/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8879 - accuracy: 0.5929 0s - loss: 0.8907 - \n",
      "Epoch 43/300\n",
      "30653/30653 [==============================] - 1s 25us/step - loss: 0.8872 - accuracy: 0.5912\n",
      "Epoch 44/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8861 - accuracy: 0.5911\n",
      "Epoch 45/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8845 - accuracy: 0.5918\n",
      "Epoch 46/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8848 - accuracy: 0.5907\n",
      "Epoch 47/300\n",
      "30653/30653 [==============================] - 1s 26us/step - loss: 0.8829 - accuracy: 0.5892\n",
      "Epoch 48/300\n",
      "30653/30653 [==============================] - 1s 26us/step - loss: 0.8802 - accuracy: 0.5898\n",
      "Epoch 49/300\n",
      "30653/30653 [==============================] - 1s 25us/step - loss: 0.8788 - accuracy: 0.5885\n",
      "Epoch 50/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8795 - accuracy: 0.5877\n",
      "Epoch 51/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8767 - accuracy: 0.5870\n",
      "Epoch 52/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8711 - accuracy: 0.5876\n",
      "Epoch 53/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8658 - accuracy: 0.5915\n",
      "Epoch 54/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8553 - accuracy: 0.5999\n",
      "Epoch 55/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8403 - accuracy: 0.6099\n",
      "Epoch 56/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8292 - accuracy: 0.6115\n",
      "Epoch 57/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8237 - accuracy: 0.6128\n",
      "Epoch 58/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8172 - accuracy: 0.6146\n",
      "Epoch 59/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8140 - accuracy: 0.6185\n",
      "Epoch 60/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8112 - accuracy: 0.6189\n",
      "Epoch 61/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8114 - accuracy: 0.6194\n",
      "Epoch 62/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8096 - accuracy: 0.6216\n",
      "Epoch 63/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8062 - accuracy: 0.6241\n",
      "Epoch 64/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8037 - accuracy: 0.6232\n",
      "Epoch 65/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8021 - accuracy: 0.6262\n",
      "Epoch 66/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8012 - accuracy: 0.6257\n",
      "Epoch 67/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8015 - accuracy: 0.6275\n",
      "Epoch 68/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7995 - accuracy: 0.6275\n",
      "Epoch 69/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.7979 - accuracy: 0.6291\n",
      "Epoch 70/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7975 - accuracy: 0.6287\n",
      "Epoch 71/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7973 - accuracy: 0.6295\n",
      "Epoch 72/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7980 - accuracy: 0.6296\n",
      "Epoch 73/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.8022 - accuracy: 0.6277\n",
      "Epoch 74/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.8027 - accuracy: 0.6275\n",
      "Epoch 75/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7984 - accuracy: 0.6306\n",
      "Epoch 76/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.7955 - accuracy: 0.6315\n",
      "Epoch 77/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7967 - accuracy: 0.6308\n",
      "Epoch 78/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7977 - accuracy: 0.6317\n",
      "Epoch 79/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.7974 - accuracy: 0.6298\n",
      "Epoch 80/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.7960 - accuracy: 0.6317\n",
      "Epoch 81/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7962 - accuracy: 0.6301\n",
      "Epoch 82/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7935 - accuracy: 0.6330\n",
      "Epoch 83/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7943 - accuracy: 0.6320\n",
      "Epoch 84/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7952 - accuracy: 0.6315\n",
      "Epoch 85/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.7929 - accuracy: 0.6326\n",
      "Epoch 86/300\n",
      "30653/30653 [==============================] - 1s 24us/step - loss: 0.7926 - accuracy: 0.6342\n",
      "Epoch 87/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7924 - accuracy: 0.6333\n",
      "Epoch 88/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7929 - accuracy: 0.6330\n",
      "Epoch 89/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7924 - accuracy: 0.6333\n",
      "Epoch 90/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7911 - accuracy: 0.6341\n",
      "Epoch 91/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7915 - accuracy: 0.6334\n",
      "Epoch 92/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7918 - accuracy: 0.6329\n",
      "Epoch 93/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7919 - accuracy: 0.6340\n",
      "Epoch 94/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7942 - accuracy: 0.6328\n",
      "Epoch 95/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7910 - accuracy: 0.6338\n",
      "Epoch 96/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7908 - accuracy: 0.6345\n",
      "Epoch 97/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7935 - accuracy: 0.6334\n",
      "Epoch 98/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7937 - accuracy: 0.6319\n",
      "Epoch 99/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7909 - accuracy: 0.6344\n",
      "Epoch 100/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7906 - accuracy: 0.6326\n",
      "Epoch 101/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7907 - accuracy: 0.6336\n",
      "Epoch 102/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7903 - accuracy: 0.6344\n",
      "Epoch 103/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7902 - accuracy: 0.6344\n",
      "Epoch 104/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7893 - accuracy: 0.6342\n",
      "Epoch 105/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7898 - accuracy: 0.6345\n",
      "Epoch 106/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7884 - accuracy: 0.6351\n",
      "Epoch 107/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7889 - accuracy: 0.6364\n",
      "Epoch 108/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7899 - accuracy: 0.6348\n",
      "Epoch 109/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7895 - accuracy: 0.6357\n",
      "Epoch 110/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7880 - accuracy: 0.6354\n",
      "Epoch 111/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7881 - accuracy: 0.6351\n",
      "Epoch 112/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7900 - accuracy: 0.6352\n",
      "Epoch 113/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7905 - accuracy: 0.6355\n",
      "Epoch 114/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7900 - accuracy: 0.6340\n",
      "Epoch 115/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7907 - accuracy: 0.6347\n",
      "Epoch 116/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7886 - accuracy: 0.6354\n",
      "Epoch 117/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7883 - accuracy: 0.6365\n",
      "Epoch 118/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7869 - accuracy: 0.6357\n",
      "Epoch 119/300\n",
      "30653/30653 [==============================] - 1s 22us/step - loss: 0.7870 - accuracy: 0.6369\n",
      "Epoch 120/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7875 - accuracy: 0.6362\n",
      "Epoch 121/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7896 - accuracy: 0.6339\n",
      "Epoch 122/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7870 - accuracy: 0.6367\n",
      "Epoch 123/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7890 - accuracy: 0.6359\n",
      "Epoch 124/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7917 - accuracy: 0.6356\n",
      "Epoch 125/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7875 - accuracy: 0.6369\n",
      "Epoch 126/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7862 - accuracy: 0.6372\n",
      "Epoch 127/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7867 - accuracy: 0.6368\n",
      "Epoch 128/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7876 - accuracy: 0.6362\n",
      "Epoch 129/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7858 - accuracy: 0.6375\n",
      "Epoch 130/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7863 - accuracy: 0.6370\n",
      "Epoch 131/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7860 - accuracy: 0.6377\n",
      "Epoch 132/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7870 - accuracy: 0.6372\n",
      "Epoch 133/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7872 - accuracy: 0.6372\n",
      "Epoch 134/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7863 - accuracy: 0.6381\n",
      "Epoch 135/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7864 - accuracy: 0.6377\n",
      "Epoch 136/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7853 - accuracy: 0.6373\n",
      "Epoch 137/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7859 - accuracy: 0.6370\n",
      "Epoch 138/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7863 - accuracy: 0.6369\n",
      "Epoch 139/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7850 - accuracy: 0.6376\n",
      "Epoch 140/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7850 - accuracy: 0.6374\n",
      "Epoch 141/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7870 - accuracy: 0.6364\n",
      "Epoch 142/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7855 - accuracy: 0.6363\n",
      "Epoch 143/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7849 - accuracy: 0.6382\n",
      "Epoch 144/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7860 - accuracy: 0.6375\n",
      "Epoch 145/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7846 - accuracy: 0.6390\n",
      "Epoch 146/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7838 - accuracy: 0.6382\n",
      "Epoch 147/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7849 - accuracy: 0.6379\n",
      "Epoch 148/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7852 - accuracy: 0.6380\n",
      "Epoch 149/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7858 - accuracy: 0.6366\n",
      "Epoch 150/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7853 - accuracy: 0.6385\n",
      "Epoch 151/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7847 - accuracy: 0.6381\n",
      "Epoch 152/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7837 - accuracy: 0.6384\n",
      "Epoch 153/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7849 - accuracy: 0.6383\n",
      "Epoch 154/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7849 - accuracy: 0.6391\n",
      "Epoch 155/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7838 - accuracy: 0.6386\n",
      "Epoch 156/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7851 - accuracy: 0.6382\n",
      "Epoch 157/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7838 - accuracy: 0.6397\n",
      "Epoch 158/300\n",
      "30653/30653 [==============================] - 1s 22us/step - loss: 0.7839 - accuracy: 0.6384\n",
      "Epoch 159/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7832 - accuracy: 0.6393\n",
      "Epoch 160/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7836 - accuracy: 0.6389\n",
      "Epoch 161/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7838 - accuracy: 0.6395\n",
      "Epoch 162/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7843 - accuracy: 0.6381\n",
      "Epoch 163/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7831 - accuracy: 0.6392\n",
      "Epoch 164/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7825 - accuracy: 0.6392\n",
      "Epoch 165/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7826 - accuracy: 0.6392\n",
      "Epoch 166/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7822 - accuracy: 0.6393\n",
      "Epoch 167/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7824 - accuracy: 0.6395\n",
      "Epoch 168/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7820 - accuracy: 0.6403\n",
      "Epoch 169/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7829 - accuracy: 0.6393\n",
      "Epoch 170/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7831 - accuracy: 0.6410\n",
      "Epoch 171/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7823 - accuracy: 0.6394\n",
      "Epoch 172/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7833 - accuracy: 0.6390\n",
      "Epoch 173/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7826 - accuracy: 0.6401\n",
      "Epoch 174/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7828 - accuracy: 0.6400\n",
      "Epoch 175/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7829 - accuracy: 0.6394\n",
      "Epoch 176/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7828 - accuracy: 0.6401\n",
      "Epoch 177/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7818 - accuracy: 0.6413\n",
      "Epoch 178/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7822 - accuracy: 0.6392\n",
      "Epoch 179/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7829 - accuracy: 0.6388\n",
      "Epoch 180/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7816 - accuracy: 0.6405\n",
      "Epoch 181/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7823 - accuracy: 0.6405\n",
      "Epoch 182/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7819 - accuracy: 0.6396\n",
      "Epoch 183/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7852 - accuracy: 0.6374\n",
      "Epoch 184/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7852 - accuracy: 0.6381\n",
      "Epoch 185/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7820 - accuracy: 0.6395\n",
      "Epoch 186/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7826 - accuracy: 0.6401\n",
      "Epoch 187/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7800 - accuracy: 0.6407\n",
      "Epoch 188/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7816 - accuracy: 0.6401\n",
      "Epoch 189/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7803 - accuracy: 0.6417\n",
      "Epoch 190/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7808 - accuracy: 0.6406\n",
      "Epoch 191/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7803 - accuracy: 0.6406\n",
      "Epoch 192/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7866 - accuracy: 0.6379\n",
      "Epoch 193/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7831 - accuracy: 0.6382\n",
      "Epoch 194/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7799 - accuracy: 0.6408\n",
      "Epoch 195/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7804 - accuracy: 0.6405\n",
      "Epoch 196/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7826 - accuracy: 0.6380\n",
      "Epoch 197/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7822 - accuracy: 0.6398\n",
      "Epoch 198/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7826 - accuracy: 0.6393\n",
      "Epoch 199/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7814 - accuracy: 0.6404\n",
      "Epoch 200/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7800 - accuracy: 0.6406\n",
      "Epoch 201/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7815 - accuracy: 0.6403\n",
      "Epoch 202/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7823 - accuracy: 0.6392\n",
      "Epoch 203/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7800 - accuracy: 0.6411\n",
      "Epoch 204/300\n",
      "30653/30653 [==============================] - 1s 22us/step - loss: 0.7815 - accuracy: 0.6415\n",
      "Epoch 205/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7792 - accuracy: 0.6406\n",
      "Epoch 206/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7790 - accuracy: 0.6415\n",
      "Epoch 207/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7804 - accuracy: 0.6405\n",
      "Epoch 208/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7800 - accuracy: 0.6409\n",
      "Epoch 209/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7792 - accuracy: 0.6406\n",
      "Epoch 210/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6396\n",
      "Epoch 211/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6400\n",
      "Epoch 212/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7796 - accuracy: 0.6415\n",
      "Epoch 213/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7788 - accuracy: 0.6402\n",
      "Epoch 214/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7792 - accuracy: 0.6411\n",
      "Epoch 215/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7784 - accuracy: 0.6419\n",
      "Epoch 216/300\n",
      "30653/30653 [==============================] - 1s 22us/step - loss: 0.7813 - accuracy: 0.6405\n",
      "Epoch 217/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7807 - accuracy: 0.6407\n",
      "Epoch 218/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7811 - accuracy: 0.6409\n",
      "Epoch 219/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7805 - accuracy: 0.6409\n",
      "Epoch 220/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7802 - accuracy: 0.6401\n",
      "Epoch 221/300\n",
      "30653/30653 [==============================] - 1s 22us/step - loss: 0.7792 - accuracy: 0.6411\n",
      "Epoch 222/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7785 - accuracy: 0.6408\n",
      "Epoch 223/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7786 - accuracy: 0.6404\n",
      "Epoch 224/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7784 - accuracy: 0.6418\n",
      "Epoch 225/300\n",
      "30653/30653 [==============================] - 1s 22us/step - loss: 0.7782 - accuracy: 0.6429\n",
      "Epoch 226/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7794 - accuracy: 0.6413\n",
      "Epoch 227/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7786 - accuracy: 0.6411\n",
      "Epoch 228/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7775 - accuracy: 0.6420\n",
      "Epoch 229/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7782 - accuracy: 0.6417\n",
      "Epoch 230/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7783 - accuracy: 0.6416\n",
      "Epoch 231/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7799 - accuracy: 0.6399\n",
      "Epoch 232/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7792 - accuracy: 0.6400\n",
      "Epoch 233/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7803 - accuracy: 0.6395\n",
      "Epoch 234/300\n",
      "30653/30653 [==============================] - 1s 22us/step - loss: 0.7777 - accuracy: 0.6431\n",
      "Epoch 235/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7765 - accuracy: 0.6426\n",
      "Epoch 236/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7779 - accuracy: 0.6425\n",
      "Epoch 237/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7794 - accuracy: 0.6413\n",
      "Epoch 238/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7782 - accuracy: 0.6419\n",
      "Epoch 239/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7768 - accuracy: 0.6429\n",
      "Epoch 240/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7772 - accuracy: 0.6428\n",
      "Epoch 241/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7760 - accuracy: 0.6441\n",
      "Epoch 242/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7774 - accuracy: 0.6424\n",
      "Epoch 243/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7778 - accuracy: 0.6413\n",
      "Epoch 244/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7791 - accuracy: 0.6413\n",
      "Epoch 245/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7782 - accuracy: 0.6416\n",
      "Epoch 246/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7780 - accuracy: 0.6417\n",
      "Epoch 247/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7763 - accuracy: 0.6419\n",
      "Epoch 248/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7810 - accuracy: 0.6414\n",
      "Epoch 249/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7786 - accuracy: 0.6405\n",
      "Epoch 250/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7764 - accuracy: 0.6412\n",
      "Epoch 251/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7759 - accuracy: 0.6416\n",
      "Epoch 252/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7766 - accuracy: 0.6434\n",
      "Epoch 253/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7772 - accuracy: 0.6425\n",
      "Epoch 254/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7761 - accuracy: 0.6434\n",
      "Epoch 255/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7753 - accuracy: 0.6429\n",
      "Epoch 256/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7753 - accuracy: 0.6435\n",
      "Epoch 257/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7777 - accuracy: 0.6421\n",
      "Epoch 258/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7793 - accuracy: 0.6408\n",
      "Epoch 259/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7783 - accuracy: 0.6421\n",
      "Epoch 260/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7767 - accuracy: 0.6423\n",
      "Epoch 261/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7772 - accuracy: 0.6422\n",
      "Epoch 262/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7755 - accuracy: 0.6438\n",
      "Epoch 263/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7750 - accuracy: 0.6432\n",
      "Epoch 264/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7751 - accuracy: 0.6437\n",
      "Epoch 265/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7751 - accuracy: 0.6429\n",
      "Epoch 266/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7737 - accuracy: 0.6445\n",
      "Epoch 267/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7741 - accuracy: 0.6442\n",
      "Epoch 268/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7747 - accuracy: 0.6441\n",
      "Epoch 269/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7744 - accuracy: 0.6438\n",
      "Epoch 270/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7737 - accuracy: 0.6443\n",
      "Epoch 271/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7745 - accuracy: 0.6440\n",
      "Epoch 272/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7747 - accuracy: 0.6436\n",
      "Epoch 273/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7738 - accuracy: 0.6440\n",
      "Epoch 274/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7747 - accuracy: 0.6442\n",
      "Epoch 275/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7754 - accuracy: 0.6447\n",
      "Epoch 276/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7746 - accuracy: 0.6450\n",
      "Epoch 277/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7748 - accuracy: 0.6433\n",
      "Epoch 278/300\n",
      "30653/30653 [==============================] - 1s 22us/step - loss: 0.7758 - accuracy: 0.6433\n",
      "Epoch 279/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7747 - accuracy: 0.6431\n",
      "Epoch 280/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7732 - accuracy: 0.6460\n",
      "Epoch 281/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7748 - accuracy: 0.6436\n",
      "Epoch 282/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7742 - accuracy: 0.6435\n",
      "Epoch 283/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7735 - accuracy: 0.6449\n",
      "Epoch 284/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7759 - accuracy: 0.6431\n",
      "Epoch 285/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7745 - accuracy: 0.6434\n",
      "Epoch 286/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7733 - accuracy: 0.6451\n",
      "Epoch 287/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7727 - accuracy: 0.6446\n",
      "Epoch 288/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7737 - accuracy: 0.6447\n",
      "Epoch 289/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7749 - accuracy: 0.6430\n",
      "Epoch 290/300\n",
      "30653/30653 [==============================] - 1s 22us/step - loss: 0.7734 - accuracy: 0.6446\n",
      "Epoch 291/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7747 - accuracy: 0.6442\n",
      "Epoch 292/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7740 - accuracy: 0.6438\n",
      "Epoch 293/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7741 - accuracy: 0.6437\n",
      "Epoch 294/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7732 - accuracy: 0.6452\n",
      "Epoch 295/300\n",
      "30653/30653 [==============================] - 1s 22us/step - loss: 0.7723 - accuracy: 0.6459\n",
      "Epoch 296/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7724 - accuracy: 0.6449\n",
      "Epoch 297/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7724 - accuracy: 0.6447\n",
      "Epoch 298/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7721 - accuracy: 0.6469\n",
      "Epoch 299/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7726 - accuracy: 0.6438\n",
      "Epoch 300/300\n",
      "30653/30653 [==============================] - 1s 23us/step - loss: 0.7727 - accuracy: 0.6450\n",
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-76a05f42840d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "history =classifier.fit(X_train, y_train, epochs = 300, batch_size = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi = 150)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc ='upper left')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6191,  337],\n",
       "        [  26,  257]],\n",
       "\n",
       "       [[6659,  149],\n",
       "        [   0,    3]],\n",
       "\n",
       "       [[4085, 1668],\n",
       "        [ 475,  583]],\n",
       "\n",
       "       [[1397,  626],\n",
       "        [1600, 3188]]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import sklearn.metrics as skm\n",
    "predictions = classifier.predict(x_test)\n",
    "y_pred = predictions>.5\n",
    "y_pred = y_pred.astype(int)\n",
    "multilabel_confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_test)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = skm.confusion_matrix(y_true.argmax(axis =1), y_pred.argmax(axis=1), labels = [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 361    0   69  164]\n",
      " [  48    3   67   34]\n",
      " [ 266    0  583 1402]\n",
      " [ 287    0  339 3188]]\n"
     ]
    }
   ],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.61      0.46       594\n",
      "           1       1.00      0.02      0.04       152\n",
      "           2       0.55      0.26      0.35      2251\n",
      "           3       0.67      0.84      0.74      3814\n",
      "\n",
      "    accuracy                           0.61      6811\n",
      "   macro avg       0.65      0.43      0.40      6811\n",
      "weighted avg       0.61      0.61      0.57      6811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skm.classification_report(y_true.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non graduates</th>\n",
       "      <th>+12</th>\n",
       "      <th>9~12</th>\n",
       "      <th>Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non graduates</th>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>+12</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9~12</th>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>583</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>287</td>\n",
       "      <td>0</td>\n",
       "      <td>339</td>\n",
       "      <td>3188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Non graduates  +12  9~12  Normal\n",
       "Non graduates            361    0    69     164\n",
       "+12                       48    3    67      34\n",
       "9~12                     266    0   583    1402\n",
       "Normal                   287    0   339    3188"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(matrix, index=['Non graduates', '+12', '9~12', 'Normal'], columns=['Non graduates', '+12', '9~12', 'Normal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out to be very inaccurate in deciding whether the student is going to graduate or not. It seems like the graduation rate is more decisive based on the performance in Junior/ Senior year. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
